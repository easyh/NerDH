{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Jupiter Notebook zum NerDH Tutorial\n",
    "\n",
    "\n",
    "[Zurück zum Web-Tutorial](https://easyh.github.io/NerDH/tut/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Erste Schritte mit spaCy\n",
    "\n",
    "Bevor wir nun mit der Erkennung von Named Entities und deren Visualisierung beginnen, lernen wir zunächts ein paar grundlegende Objekte und Funktionen von spacy kennen. Bis auf den ersten Codeteil sind die anderen NLP-Funktionen für unsere NER-Aufgabe nicht wichtig, sollen aber dennoch kurz vorgestellt werden, da sie wichtige Grundlagen für Textanalysen sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zuerst importieren wir spaCy\n",
    "import spacy\n",
    "\n",
    "#in der Variable text ist der Text gespeichert, der analysiert werden soll.\n",
    "text = \"Mia Müller wohnt in Trier und studiert an der Universität Trier. Aufgewachsen ist sie in München mit ihrem Bruder Tom.\"\n",
    "\n",
    "#Als nächstes müssen wir ein Modellobjekt laden. \n",
    "#Hierfür verwenden wir die Funktion spacy.load(). \n",
    "#Diese nimmt ein Argument entgegen, nämlich das Modell, das wir laden möchten.\n",
    "#Wir werden das mittlere deutsche Modell verwenden.\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "\n",
    "#Nachdem wir das nlp-Objekt erstellt haben, können wir es verwenden, um einen Text zu analysieren.\n",
    "#Zu diesem Zweck erstellen wir ein doc-Objekt.\n",
    "#Dieses Objekt wird eine Menge Daten über den Text enthalten.\n",
    "doc = nlp(text)\n",
    "\n",
    "#Wir testen, ob das doc-Objekt unseren Text übernommen hat.\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hier verwenden wir den Sentence-Tokenizer, um einen Text in einzelne Sätze zu unterteilen. \n",
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hier verwenden wir das Part-of-Speech Tagging\n",
    "for token in doc: \n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hiermit extrahieren wir Substantive und Substantiv-Bausteine.\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hiermit können wir Verben in einem Text ermitteln.\n",
    "#Verben sind im POS-TAg als \"VERB\" oder \"AUX\" definiert, daher iterieren wir über alle POS-TAGS, die übereinstimmen.\n",
    "verbs = [\"VERB\", \"AUX\"]\n",
    "for token in doc:\n",
    "    if token.pos_ in verbs:\n",
    "        print (token.text, token.pos_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatisierung\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Entitäten erkennen \n",
    "\n",
    "Der Code um Named Entities in einem Dokument zu erkennen ist ähnlich simpel wie der Code der anderen Funktionen. Wir iterieren erneut über unser `doc-Objekt` mit der Funktion `.ents`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#named entity recognition(ner)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text,ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um beispielsweise nur die benannten Entitäten zu extrahieren, die als PERSON identifiziert wurden, können wir eine einfache if-Anweisung in den Mix einfügen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"PER\":\n",
    "       print(ent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können uns zusätzlich noch ausgeben lassen, an welcher Stelle im Text die Named Entities zu finden sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ner mit mehr Informationsausgabe\n",
    "for ent in doc.ents:\n",
    "        print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 NER visualisieren\n",
    "\n",
    "`spaCy` hat eine eingebaute Funktion zur Visualisierung der Entitäten namens `displacy`. Der schnellste Weg, ein `doc-Objekt` zu visualisieren ist `displacy.serve`. Dadurch wird ein einfacher Webserver gestartet und das Ergebnis kann im Browser betrachtet werden. Da wir innerhalb eines Jupyter Notebooks arbeiten, verwenden wir die Funktion `displacy.render`. Dazu müssen wir zunächst noch `displacy` importieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy \n",
    "\n",
    "displacy.render(doc, style=\"ent\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier können wir jetzt noch eigene Anpassungen wie die Auswahl der Entitäten oder auch die Farbe ausführen. Die individuellen Farben geben wir für alle vier Entitätstypen an, allerdings wollen wir uns hier nur die Personen (`PER`) und Orte (`LOC`) ausgeben lassen.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\"PER\": \"#fdec3e\", \"LOC\": \"#7e56c2\", \"ORG\": \"#209485\" , \"MISC\": \"#eb4034\"}\n",
    "options = {\"ents\": [\"PER\", \"LOC\"], \"colors\": colors}\n",
    "\n",
    "displacy.render(doc, style=\"ent\", options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da wir es hier mit einem vergleichsweise sehr simplen Beispieltext zu tun haben, ist das sehr gute Ergebnis nicht wirklich überraschend. Daher wollen wir an dieser Stelle kurz zeigen, wie das Standardmodell mit einem Satz aus dem frühneuhochdeutschen abschneidet. Der Satz ist aus unserem Trainingstext [**München 1611**](https://hainhofer.hab.de/reiseberichte/muenchen1611?v={%22view%22:%22info%22})."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardmodell testen mit frühneuhochdeutschen Beispieltext \n",
    "text_fnhd = \"Aines mörders Conterfett, genant Christoff Froschhammer von Vlingingen, der Hat 345 mörd, mit seiner aignen hand, vnd 400 mord in gesellschafft anderer, gethan, ist Anno 1578 zu Welß in Steÿrmarck gerichtet worden, vnd auß dem stifft Saltzburg gebürtig gewesen.\"\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "doc_fnhd = nlp(text_fnhd)\n",
    "for ent in doc_fnhd.ents:\n",
    "    print(ent.text,ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\"PER\": \"#fdec3e\", \"LOC\": \"#7e56c2\", \"ORG\": \"#209485\" , \"MISC\": \"#eb4034\"}\n",
    "options = {\"ents\": [\"PER\", \"LOC\", \"ORG\", \"MISC\"], \"colors\": colors}\n",
    "\n",
    "displacy.render(doc_fnhd, style=\"ent\", options=options)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
