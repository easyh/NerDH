{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"NER Tutorial am Beispiel deutscher historischer Texte Das NerDH-Tutorial ist im Rahmen einer Masterarbeit an der Universit\u00e4t Trier im Wintersemester 2022/23 entstanden. Das Thema der Arbeit war Named Entity Recognition: Einsatz und Verwendung der Technologie in den Digital Humanities . Daraus leitet sich auch der Name des Tutorials ab: NER steht f\u00fcr die Abk\u00fcrzung von Named Entity Recognition und DH f\u00fcr Digital Humanities. Im praktischen Teil der Arbeit wurde mit dem NER-Tool spaCy ein eigenes Modell f\u00fcr fr\u00fchneuhochdeutsche Texte trainiert. Fr\u00fchneuhochdeutsch Die Periode des Fr\u00fchneuhochdeutschen (Fnhd.) ist zwischen dem mittelalterlichen und neuzeitlichen Deutsch angesiedelt und erstreckt sich \u00fcber einen Zeitraum von circa 1350-1650. 1 Ziel dieses Web-Tutorials ist es nun Interessierten grundlegende Kenntnisse in Bezug auf Named Entity Recognition sowie die praktische Anwendung eines NER-Tools zu vermitteln. Somit kann dieses Tutorial in zwei Teile gegliedert werden: Theorie und praktische Anwendung . Der praktische Teil wird dabei neben einer Einf\u00fchrung in spaCy den Trainingsprozess des fr\u00fchneuhochdeutschen NER-Modells erkl\u00e4ren. Abgerundet wird das Web-Tutorial durch den NerDH-Visualisierer , welcher mit einer grafischen Benutzeroberfl\u00e4che f\u00fcr eine einfache Ermittlung von Named Entities in deutschen (historischen) Texten sorgt. Viel Spa\u00df und Erfolg mit dem Tutorial! 1. Was ist Named Entity Recognition (NER)? Named Entity Recognition (NER) ist ein Textanalyse Verfahren des Natural Language Processing (NLP), welches sich mit der Identifizierung und Klassifizierung von benannten Entit\u00e4ten ( Named Entities ) besch\u00e4ftigt. Mit Entit\u00e4ten werden Dinge der realen Welt bezeichnet, die einen Namen haben k\u00f6nnen. Die klassischen Entit\u00e4ten in NER-Modellen sind: PERSONEN , ORTE und ORGANISATIONEN . Beispiel Mia M\u00fcller PER wohnt in Trier LOC und studiert an der Universit\u00e4t Trier. ORG 2. Warum NER? Der Einsatz von NER bedeutet eine enorme Zeitersparnis gegen\u00fcber der manuellen Annotation von Named Entities in Texten. NER ist n\u00fctzlich, um Schl\u00fcsselinformationen aus Texten zu extrahieren. Zum Beispiel k\u00f6nnte NER genutzt werden, um die am h\u00e4ufigsten vorkommenden Figuren in einem Roman zu identifzieren oder ein Netz von Figuren zu erstellen. NER k\u00f6nnte aber auch verwendet werden, um die in Texten erw\u00e4hnten geografischen Orte zu identifizieren, was der erste Schritt f\u00fcr die Kartierung von Orten w\u00e4re. Damit macht NER vor allem bei der Analyse von gro\u00dfen Textmengen Sinn, um Daten f\u00fcr weitere Analyseschritte zu erhalten. 3. NER in den Digital Humanities Named Entity Recognition funktioniert besonders gut mit Zeitungsdaten - einfach aus dem Grund, weil die Systeme vor allem mit solchen Daten trainiert wurden. Allerdings wird NER auch in vielen anderen spezifischen Bereichen angewandt. F\u00fcr die Digital Humanities wurden NER-Systeme besonders durch die massive Anzahl an digitalisierten historischen Dokumenten interessant. Allerdings haben sich die Entwickler von NER-Modellen beim Training haups\u00e4chlich auf moderne und englischsprachige Texte konzentriert. Besonders bei historischen Texten schneiden NER-Modelle nicht gut ab. F\u00fcr die Digital Humanities ist es daher oft sehr herausfordernd mit aktuellen NER-Tools zu arbeiten, da man in den meisten F\u00e4llen nicht mit standardisierten und modernen Sprachen arbeitet. Meist - wie auch in diesem Tutorial - arbeitet man mit seltenen oder alten Sprachen. Bei einem solchen Textkorpus f\u00fchren standardisierte NER-Modelle zu hohen Fehlerquoten. Herausfordernd ist dabei vor allem die Heterogenit\u00e4t der historischen Dokumente. Denn innerhalb eines Korpus oder sogar eines Dokumentes sind verschiedene Sprachen (z.B. Deutsch, Latein, Franz\u00f6sisch), eine uneinheitliche Schreibweise und Fehler in der Transkription durch Schreiber bzw. Texterkennungssoftware wie OCR vorfinden. Das folgende Bild stammt aus dem Annotationsprozess des Goldstandards f\u00fcr das Training mit dem fr\u00fchhochneudeutschen Text und soll einen kleinen Einblick auf die uneinheitliche Schreibweise zeigen: Goldstandard Ein Goldstandard ist die finale Version der annotierten Daten, die f\u00fcr den Trainingsprozess verwendet werden. Je besser und genauer die Auszeichnungen f\u00fcr den Goldstandard gemacht werden, desto besser ist das Trainingsergebnis. Erstellung des Goldstandards f\u00fcr das Training. Wir sehen, dass hier besonders die Ortsnamen eine untypische Schreibweise im Vergleich zu deren heutiger aufweisen. Ebenso erkennen wir den Mix der verschiedenen Sprachen, da hier Anno verwendet wird, was lateinisch ist und im Jahr bedeutet. All diese Faktoren k\u00f6nnen die Genauigkeit von NER stark beeinflussen. Das Problem ist in den Digital Humanities bekannt. Vereinzelt wurden daher bereits auch schon experimentell Modelle und Untersuchungen mit deutschen historischen Texte trainiert und gemacht. 2 3 4 Genau das werden wir auch wir im praktischen Teil des Tutorials angehen. 4. Der NER-Prozess Der Named Entity Recognition Prozess l\u00e4sst sich in zwei Schritte aufteilen: 5 Extraktion von Entit\u00e4ten: In diesem Schritt scannt das NER-Modell die Daten und findet die W\u00f6rter, die als Entit\u00e4t behandelt werden k\u00f6nnen. Ein NER-Modell ist in der Lage, die benannte Entit\u00e4t im Modell auf der Grundlage der ihm bekannten benannten Entit\u00e4ten zu finden. Klassifizierung von Entit\u00e4ten: Hier werden die Entit\u00e4ten in vordefinierte Klassen kategorisiert, die benannte Entit\u00e4t Trier w\u00fcrde beispielsweise als ORT kategorisiert werden. Die meisten NER-Tools basieren auf Machine-Learning Algorithmen. Hier wird vorher eine Reihe von Merkmalen (Features) definiert, um eine m\u00f6glichst pr\u00e4zise Erkennung m\u00f6glich zu machen. Zum Beispiel k\u00f6nnen Wortlisten ber\u00fccksichtigt werden, die alle Namen von Personen, Orten und Organisationen verzeichnet, die vorkommen k\u00f6nnten. Zus\u00e4tzlich k\u00f6nnen auch W\u00f6rter mit einbezogen werden, die sich entweder vor oder nach der benannten Entit\u00e4t befinden. Weitere Merkmale k\u00f6nnten auch h\u00e4ufig vorher genannte W\u00f6rter sein, sowie zum Beispiel bei Orten das Wort in . Ein anderes erlernbares Muster k\u00f6nnte das Darstellungsformat bei Daten sein (z.B. 01.01.2023 oder 1. Januar 2023). Eine wichtige Rolle spielen auch Merkmale wie Gro\u00df- und Kleinschreibung sowie Positionen im Satz. S\u00e4mtliche Tools die es gibt, unterscheiden sich u.a. genau in diesem Punkt, der Anzahl der verschiedenen Merkmale. 6 Mit Hilfe dieser im Tool vordefinierten Merkmale findet dann der \u00fcberwachte Machine Learning Prozess statt. Der Lernprozess des NER-Tools besteht darin, dass diese Merkmale mit einem manuell annotierten Text (ein Teil des Goldstandards) abgeglichen werden, dem sogenannten Trainingskorpus. Das Ergebnis dieses Abgleichs ist dann das NER-Modell. Da Entit\u00e4ten meist unterschiedliche Bedeutungen tragen k\u00f6nnen, f\u00fchrt nur die Kombination verschiedener Merkmale zu guten Ergebnissen. Das Tool errechnet anhand der Feature-Kombinationen und der Trainingsdaten, welche Zuordnung in welchem Kontext wahrscheinlicher ist. Named Entity Linking & Beziehungsextraktion Der Standardprozess kann allerdings noch um zwei weitere Schritte erweitert werden, die bei NER eine wichtige Rolle spielen: 7 Disambiguation/Linking: Hier wird den gefundenen Entit\u00e4ten eine eindeutige Referenz wie z.B. ein Wikidata-Eintrag hinzuf\u00fcgt. In unserem Beispiel Trier als Entit\u00e4t ORT w\u00fcrde der entsprechende Wikidata-Eintrag von Trier Q3138 verlinkt werden. Wikidata-Eintrag Wikidata ist eine globale Wissensdatenbank, wo es f\u00fcr jeden Eintrag einen persistenten Identifikator (QID) gibt. F\u00fcr die Stadt Trier w\u00e4re der persistente Identifikator Q3138 . Hierdurch kann eine Entit\u00e4t eindeutig identifiziert und verlinkt werden. Beziehungsexktraktion: In diesem Schritt k\u00f6nnen Beziehungen zwischen den benannten Entit\u00e4ten hergestellt werden. In einem Text werden m\u00f6glicherweise Ortsnamen erkannt und als Named Entities markiert. Mit Beziehungserkennung kann dann untersucht werden, welche Beziehungen zwischen diesen Ortsnamen bestehen. Im Beispieltext Trier ist eine Stadt in Deutschland und liegt in der N\u00e4he der Grenze zu Luxemburg. w\u00fcrden Trier , Deutschland und Luxemburg als Named Entities markiert. Durch die Beziehungserkennung k\u00f6nnte erkannt werden das Trier eine Stadt in Deutschland ist und Deutschland und Luxemburg Nachbarl\u00e4nder sind. 5. \u00dcbersicht \u00fcber NER Tools Es gibt eine Vielzahl von vorhandenen NER-Tools. Meist wurden diese mit gro\u00dfen Korpora aus modernen journalistischen Texten trainiert. Speziell f\u00fcr die DH ist es daher wichtig, auf die Anwendungs- und Trainingsm\u00f6glichkeiten der Tools zu achten. Da wir im Tutorial nur mit dem Tool spaCy arbeiten werden, soll die folgende Tabelle einen \u00dcberblick \u00fcber Tools bieten, die ebenfalls in den Digital Humanities zum Einsatz kommen. Tool Beschreibung Link spaCy Spacy ist ein leistungsstarkes Tool f\u00fcr die Verarbeitung nat\u00fcrlicher Sprache, das zur Verarbeitung gro\u00dfer Datenmengen eingesetzt wird. Mit Unterst\u00fctzung f\u00fcr mehr als 64 Sprachen und 63 trainierten Pipelines f\u00fcr 19 Sprachen, ist es ein praktisches Tool f\u00fcr NLP. Das Trainieren einer eigenen Pipeline erm\u00f6glicht die Anwendung auf spezifische Texte. Link NLTK Das NLTK (Natural Language Toolkit) ist eine Reihe von Bibliotheken, die f\u00fcr NLP verwendet werden. Es wird h\u00e4ufig in der Forschung und f\u00fcr Bildungszwecke verwendet. Es ist in Python geschrieben und hat Zugang zu mehr als 50 Textkorpora in 7 Sprachen. Link Stanford NER Stanford NER ist eins der bekanntesten NER Tools unter Geisteswissenschaftlern, da es mehrere vortrainierte Modelle in verschiedenen Sprachen besitzt und eine M\u00f6glichkeit f\u00fcr die Erstellung von eigenen Modellen bietet. Link HER Das HER-Tool (Humanities Entity Recognizer) wurde speziell f\u00fcr die Digital Humanities entwickelt. Es bietet eine Whitebox-L\u00f6sung f\u00fcr den robusten Umgang mit verschiedenen Arten von Entit\u00e4ten, verschiedenen Sprachen, Stilen und Dom\u00e4nen sowie unterschiedlichen Strukturierungsebenen in Texten an. Link WebLicht WebLicht ist eine webbasierte Anwendung f\u00fcr automatische Annotation von Textkorpora, welche sowohl verschiedene Services f\u00fcr die Verarbeitung von Daten anbietet, als auch eine anwenderfreundliche grafische Oberfl\u00e4che f\u00fcr die Verkettung von verschiedenen linguistischen Anwendungen. WebLicht bietet auch mehrere Pipelines f\u00fcr deutschsprachige NER an. Link Flair Flair ist eine leistungsstarke NLP-Bibliothek in einem PyTorch-Framework, welches es einfach macht, eigene Modelle zu trainieren und mit neuen Ans\u00e4tzen zu experimentieren, die Flair-Einbettungen und -Klassen verwenden. Link TAGME TAGME ist ein leistungsf\u00e4higes Werkzeug, das in der Lage ist, in einem unstrukturierten Text Entit\u00e4ten zu identifizieren und sie auf schnelle und effektive Weise mit einer entsprechenden Wikipedia-Seite zu verkn\u00fcpfen (Named Entity Linking). Link DBPedia DPPedia ist ein Tool zur automatischen Annotation von DBpedia-Ressourcen in Texten und bietet eine L\u00f6sung f\u00fcr die Verkn\u00fcpfung unstrukturierter Informationsquellen mit der Linked Open Data Cloud durch DBpedia (Named Entity Linking). Link Wikimedia Foundation. (2022). Fr\u00fchneuhochdeutsche Sprache. Wikipedia. https://de.wikipedia.org/wiki/Fr\u00fchneuhochdeutsche_Sprache \u21a9 More, Jacqueline. Theorie und Anwendung von Named Entity Recognition in den Digital Humanities mit Fokus auf historische Texte des 17. Jahrhunderts (2021). https://github.com/jackymore/NER_historical_texts \u21a9 Ehrmann, M., Hamdi, A., Pontes, E. L., Romanello, M., & Doucet, A. (2021). Named entity recognition and classification on historical documents: A survey. https://arxiv.org/pdf/2109.11406.pdf \u21a9 Labusch, K., Kulturbesitz, P., Neudecker, C., & Zellh\u00f6fer, D. (2019). BERT for named entity recognition in contemporary and historical German. In Proceedings of the 15th conference on natural language processing (S. 9-11). https://corpora.linguistik.uni-erlangen.de/data/konvens/proceedings/papers/KONVENS2019_paper_4.pdf \u21a9 Aruja, M. P. (2022). Top 3 Packages for Named Entity Recognition - Quantrium.ai. Medium. https://medium.com/quantrium-tech/top-3-packages-for-named-entity-recognition-e9e14f6f0a2a \u21a9 Named Entity Recognition (NER) | forTEXT. (o. D.). https://fortext.net/routinen/methoden/named-entity-recognition-ner \u21a9 Ehrmann, M., Nouvel, D. & Rosset, S. (2016). Named Entity Resources - Overview and Outlook. Language Resources and Evaluation. https://hal-inalco.archives-ouvertes.fr/hal-01359441/document \u21a9","title":"Named Entity Recognition"},{"location":"#ner-tutorial-am-beispiel-deutscher-historischer-texte","text":"Das NerDH-Tutorial ist im Rahmen einer Masterarbeit an der Universit\u00e4t Trier im Wintersemester 2022/23 entstanden. Das Thema der Arbeit war Named Entity Recognition: Einsatz und Verwendung der Technologie in den Digital Humanities . Daraus leitet sich auch der Name des Tutorials ab: NER steht f\u00fcr die Abk\u00fcrzung von Named Entity Recognition und DH f\u00fcr Digital Humanities. Im praktischen Teil der Arbeit wurde mit dem NER-Tool spaCy ein eigenes Modell f\u00fcr fr\u00fchneuhochdeutsche Texte trainiert. Fr\u00fchneuhochdeutsch Die Periode des Fr\u00fchneuhochdeutschen (Fnhd.) ist zwischen dem mittelalterlichen und neuzeitlichen Deutsch angesiedelt und erstreckt sich \u00fcber einen Zeitraum von circa 1350-1650. 1 Ziel dieses Web-Tutorials ist es nun Interessierten grundlegende Kenntnisse in Bezug auf Named Entity Recognition sowie die praktische Anwendung eines NER-Tools zu vermitteln. Somit kann dieses Tutorial in zwei Teile gegliedert werden: Theorie und praktische Anwendung . Der praktische Teil wird dabei neben einer Einf\u00fchrung in spaCy den Trainingsprozess des fr\u00fchneuhochdeutschen NER-Modells erkl\u00e4ren. Abgerundet wird das Web-Tutorial durch den NerDH-Visualisierer , welcher mit einer grafischen Benutzeroberfl\u00e4che f\u00fcr eine einfache Ermittlung von Named Entities in deutschen (historischen) Texten sorgt. Viel Spa\u00df und Erfolg mit dem Tutorial!","title":"NER Tutorial am Beispiel deutscher historischer Texte"},{"location":"#1-was-ist-named-entity-recognition-ner","text":"Named Entity Recognition (NER) ist ein Textanalyse Verfahren des Natural Language Processing (NLP), welches sich mit der Identifizierung und Klassifizierung von benannten Entit\u00e4ten ( Named Entities ) besch\u00e4ftigt. Mit Entit\u00e4ten werden Dinge der realen Welt bezeichnet, die einen Namen haben k\u00f6nnen. Die klassischen Entit\u00e4ten in NER-Modellen sind: PERSONEN , ORTE und ORGANISATIONEN . Beispiel Mia M\u00fcller PER wohnt in Trier LOC und studiert an der Universit\u00e4t Trier. ORG","title":"1. Was ist Named Entity Recognition (NER)?"},{"location":"#2-warum-ner","text":"Der Einsatz von NER bedeutet eine enorme Zeitersparnis gegen\u00fcber der manuellen Annotation von Named Entities in Texten. NER ist n\u00fctzlich, um Schl\u00fcsselinformationen aus Texten zu extrahieren. Zum Beispiel k\u00f6nnte NER genutzt werden, um die am h\u00e4ufigsten vorkommenden Figuren in einem Roman zu identifzieren oder ein Netz von Figuren zu erstellen. NER k\u00f6nnte aber auch verwendet werden, um die in Texten erw\u00e4hnten geografischen Orte zu identifizieren, was der erste Schritt f\u00fcr die Kartierung von Orten w\u00e4re. Damit macht NER vor allem bei der Analyse von gro\u00dfen Textmengen Sinn, um Daten f\u00fcr weitere Analyseschritte zu erhalten.","title":"2. Warum NER?"},{"location":"#3-ner-in-den-digital-humanities","text":"Named Entity Recognition funktioniert besonders gut mit Zeitungsdaten - einfach aus dem Grund, weil die Systeme vor allem mit solchen Daten trainiert wurden. Allerdings wird NER auch in vielen anderen spezifischen Bereichen angewandt. F\u00fcr die Digital Humanities wurden NER-Systeme besonders durch die massive Anzahl an digitalisierten historischen Dokumenten interessant. Allerdings haben sich die Entwickler von NER-Modellen beim Training haups\u00e4chlich auf moderne und englischsprachige Texte konzentriert. Besonders bei historischen Texten schneiden NER-Modelle nicht gut ab. F\u00fcr die Digital Humanities ist es daher oft sehr herausfordernd mit aktuellen NER-Tools zu arbeiten, da man in den meisten F\u00e4llen nicht mit standardisierten und modernen Sprachen arbeitet. Meist - wie auch in diesem Tutorial - arbeitet man mit seltenen oder alten Sprachen. Bei einem solchen Textkorpus f\u00fchren standardisierte NER-Modelle zu hohen Fehlerquoten. Herausfordernd ist dabei vor allem die Heterogenit\u00e4t der historischen Dokumente. Denn innerhalb eines Korpus oder sogar eines Dokumentes sind verschiedene Sprachen (z.B. Deutsch, Latein, Franz\u00f6sisch), eine uneinheitliche Schreibweise und Fehler in der Transkription durch Schreiber bzw. Texterkennungssoftware wie OCR vorfinden. Das folgende Bild stammt aus dem Annotationsprozess des Goldstandards f\u00fcr das Training mit dem fr\u00fchhochneudeutschen Text und soll einen kleinen Einblick auf die uneinheitliche Schreibweise zeigen: Goldstandard Ein Goldstandard ist die finale Version der annotierten Daten, die f\u00fcr den Trainingsprozess verwendet werden. Je besser und genauer die Auszeichnungen f\u00fcr den Goldstandard gemacht werden, desto besser ist das Trainingsergebnis. Erstellung des Goldstandards f\u00fcr das Training. Wir sehen, dass hier besonders die Ortsnamen eine untypische Schreibweise im Vergleich zu deren heutiger aufweisen. Ebenso erkennen wir den Mix der verschiedenen Sprachen, da hier Anno verwendet wird, was lateinisch ist und im Jahr bedeutet. All diese Faktoren k\u00f6nnen die Genauigkeit von NER stark beeinflussen. Das Problem ist in den Digital Humanities bekannt. Vereinzelt wurden daher bereits auch schon experimentell Modelle und Untersuchungen mit deutschen historischen Texte trainiert und gemacht. 2 3 4 Genau das werden wir auch wir im praktischen Teil des Tutorials angehen.","title":"3. NER in den Digital Humanities"},{"location":"#4-der-ner-prozess","text":"Der Named Entity Recognition Prozess l\u00e4sst sich in zwei Schritte aufteilen: 5 Extraktion von Entit\u00e4ten: In diesem Schritt scannt das NER-Modell die Daten und findet die W\u00f6rter, die als Entit\u00e4t behandelt werden k\u00f6nnen. Ein NER-Modell ist in der Lage, die benannte Entit\u00e4t im Modell auf der Grundlage der ihm bekannten benannten Entit\u00e4ten zu finden. Klassifizierung von Entit\u00e4ten: Hier werden die Entit\u00e4ten in vordefinierte Klassen kategorisiert, die benannte Entit\u00e4t Trier w\u00fcrde beispielsweise als ORT kategorisiert werden. Die meisten NER-Tools basieren auf Machine-Learning Algorithmen. Hier wird vorher eine Reihe von Merkmalen (Features) definiert, um eine m\u00f6glichst pr\u00e4zise Erkennung m\u00f6glich zu machen. Zum Beispiel k\u00f6nnen Wortlisten ber\u00fccksichtigt werden, die alle Namen von Personen, Orten und Organisationen verzeichnet, die vorkommen k\u00f6nnten. Zus\u00e4tzlich k\u00f6nnen auch W\u00f6rter mit einbezogen werden, die sich entweder vor oder nach der benannten Entit\u00e4t befinden. Weitere Merkmale k\u00f6nnten auch h\u00e4ufig vorher genannte W\u00f6rter sein, sowie zum Beispiel bei Orten das Wort in . Ein anderes erlernbares Muster k\u00f6nnte das Darstellungsformat bei Daten sein (z.B. 01.01.2023 oder 1. Januar 2023). Eine wichtige Rolle spielen auch Merkmale wie Gro\u00df- und Kleinschreibung sowie Positionen im Satz. S\u00e4mtliche Tools die es gibt, unterscheiden sich u.a. genau in diesem Punkt, der Anzahl der verschiedenen Merkmale. 6 Mit Hilfe dieser im Tool vordefinierten Merkmale findet dann der \u00fcberwachte Machine Learning Prozess statt. Der Lernprozess des NER-Tools besteht darin, dass diese Merkmale mit einem manuell annotierten Text (ein Teil des Goldstandards) abgeglichen werden, dem sogenannten Trainingskorpus. Das Ergebnis dieses Abgleichs ist dann das NER-Modell. Da Entit\u00e4ten meist unterschiedliche Bedeutungen tragen k\u00f6nnen, f\u00fchrt nur die Kombination verschiedener Merkmale zu guten Ergebnissen. Das Tool errechnet anhand der Feature-Kombinationen und der Trainingsdaten, welche Zuordnung in welchem Kontext wahrscheinlicher ist. Named Entity Linking & Beziehungsextraktion Der Standardprozess kann allerdings noch um zwei weitere Schritte erweitert werden, die bei NER eine wichtige Rolle spielen: 7 Disambiguation/Linking: Hier wird den gefundenen Entit\u00e4ten eine eindeutige Referenz wie z.B. ein Wikidata-Eintrag hinzuf\u00fcgt. In unserem Beispiel Trier als Entit\u00e4t ORT w\u00fcrde der entsprechende Wikidata-Eintrag von Trier Q3138 verlinkt werden. Wikidata-Eintrag Wikidata ist eine globale Wissensdatenbank, wo es f\u00fcr jeden Eintrag einen persistenten Identifikator (QID) gibt. F\u00fcr die Stadt Trier w\u00e4re der persistente Identifikator Q3138 . Hierdurch kann eine Entit\u00e4t eindeutig identifiziert und verlinkt werden. Beziehungsexktraktion: In diesem Schritt k\u00f6nnen Beziehungen zwischen den benannten Entit\u00e4ten hergestellt werden. In einem Text werden m\u00f6glicherweise Ortsnamen erkannt und als Named Entities markiert. Mit Beziehungserkennung kann dann untersucht werden, welche Beziehungen zwischen diesen Ortsnamen bestehen. Im Beispieltext Trier ist eine Stadt in Deutschland und liegt in der N\u00e4he der Grenze zu Luxemburg. w\u00fcrden Trier , Deutschland und Luxemburg als Named Entities markiert. Durch die Beziehungserkennung k\u00f6nnte erkannt werden das Trier eine Stadt in Deutschland ist und Deutschland und Luxemburg Nachbarl\u00e4nder sind.","title":"4. Der NER-Prozess"},{"location":"#5-ubersicht-uber-ner-tools","text":"Es gibt eine Vielzahl von vorhandenen NER-Tools. Meist wurden diese mit gro\u00dfen Korpora aus modernen journalistischen Texten trainiert. Speziell f\u00fcr die DH ist es daher wichtig, auf die Anwendungs- und Trainingsm\u00f6glichkeiten der Tools zu achten. Da wir im Tutorial nur mit dem Tool spaCy arbeiten werden, soll die folgende Tabelle einen \u00dcberblick \u00fcber Tools bieten, die ebenfalls in den Digital Humanities zum Einsatz kommen. Tool Beschreibung Link spaCy Spacy ist ein leistungsstarkes Tool f\u00fcr die Verarbeitung nat\u00fcrlicher Sprache, das zur Verarbeitung gro\u00dfer Datenmengen eingesetzt wird. Mit Unterst\u00fctzung f\u00fcr mehr als 64 Sprachen und 63 trainierten Pipelines f\u00fcr 19 Sprachen, ist es ein praktisches Tool f\u00fcr NLP. Das Trainieren einer eigenen Pipeline erm\u00f6glicht die Anwendung auf spezifische Texte. Link NLTK Das NLTK (Natural Language Toolkit) ist eine Reihe von Bibliotheken, die f\u00fcr NLP verwendet werden. Es wird h\u00e4ufig in der Forschung und f\u00fcr Bildungszwecke verwendet. Es ist in Python geschrieben und hat Zugang zu mehr als 50 Textkorpora in 7 Sprachen. Link Stanford NER Stanford NER ist eins der bekanntesten NER Tools unter Geisteswissenschaftlern, da es mehrere vortrainierte Modelle in verschiedenen Sprachen besitzt und eine M\u00f6glichkeit f\u00fcr die Erstellung von eigenen Modellen bietet. Link HER Das HER-Tool (Humanities Entity Recognizer) wurde speziell f\u00fcr die Digital Humanities entwickelt. Es bietet eine Whitebox-L\u00f6sung f\u00fcr den robusten Umgang mit verschiedenen Arten von Entit\u00e4ten, verschiedenen Sprachen, Stilen und Dom\u00e4nen sowie unterschiedlichen Strukturierungsebenen in Texten an. Link WebLicht WebLicht ist eine webbasierte Anwendung f\u00fcr automatische Annotation von Textkorpora, welche sowohl verschiedene Services f\u00fcr die Verarbeitung von Daten anbietet, als auch eine anwenderfreundliche grafische Oberfl\u00e4che f\u00fcr die Verkettung von verschiedenen linguistischen Anwendungen. WebLicht bietet auch mehrere Pipelines f\u00fcr deutschsprachige NER an. Link Flair Flair ist eine leistungsstarke NLP-Bibliothek in einem PyTorch-Framework, welches es einfach macht, eigene Modelle zu trainieren und mit neuen Ans\u00e4tzen zu experimentieren, die Flair-Einbettungen und -Klassen verwenden. Link TAGME TAGME ist ein leistungsf\u00e4higes Werkzeug, das in der Lage ist, in einem unstrukturierten Text Entit\u00e4ten zu identifizieren und sie auf schnelle und effektive Weise mit einer entsprechenden Wikipedia-Seite zu verkn\u00fcpfen (Named Entity Linking). Link DBPedia DPPedia ist ein Tool zur automatischen Annotation von DBpedia-Ressourcen in Texten und bietet eine L\u00f6sung f\u00fcr die Verkn\u00fcpfung unstrukturierter Informationsquellen mit der Linked Open Data Cloud durch DBpedia (Named Entity Linking). Link Wikimedia Foundation. (2022). Fr\u00fchneuhochdeutsche Sprache. Wikipedia. https://de.wikipedia.org/wiki/Fr\u00fchneuhochdeutsche_Sprache \u21a9 More, Jacqueline. Theorie und Anwendung von Named Entity Recognition in den Digital Humanities mit Fokus auf historische Texte des 17. Jahrhunderts (2021). https://github.com/jackymore/NER_historical_texts \u21a9 Ehrmann, M., Hamdi, A., Pontes, E. L., Romanello, M., & Doucet, A. (2021). Named entity recognition and classification on historical documents: A survey. https://arxiv.org/pdf/2109.11406.pdf \u21a9 Labusch, K., Kulturbesitz, P., Neudecker, C., & Zellh\u00f6fer, D. (2019). BERT for named entity recognition in contemporary and historical German. In Proceedings of the 15th conference on natural language processing (S. 9-11). https://corpora.linguistik.uni-erlangen.de/data/konvens/proceedings/papers/KONVENS2019_paper_4.pdf \u21a9 Aruja, M. P. (2022). Top 3 Packages for Named Entity Recognition - Quantrium.ai. Medium. https://medium.com/quantrium-tech/top-3-packages-for-named-entity-recognition-e9e14f6f0a2a \u21a9 Named Entity Recognition (NER) | forTEXT. (o. D.). https://fortext.net/routinen/methoden/named-entity-recognition-ner \u21a9 Ehrmann, M., Nouvel, D. & Rosset, S. (2016). Named Entity Resources - Overview and Outlook. Language Resources and Evaluation. https://hal-inalco.archives-ouvertes.fr/hal-01359441/document \u21a9","title":"5. \u00dcbersicht \u00fcber NER Tools"},{"location":"gui/","text":"NerDH Visualisierer Der Abschluss des Tutorials stellt der NerDH-Visualisierer dar. Er kommt mit einer einfachen und leicht zu bedienenden Benutzeroberfl\u00e4che, um einen Text schnell auf seine Named Entities zu untersuchen. Der Visualisierer wurde mit dem Open Source App Framework streamlit erstellt. Streamlit Streamlit konvertiert pythonbasierte Datenskripte zu Webanwendungen und hostet sie dabei kostenlos. M\u00f6glich ist dies durch die Verkn\u00fcpfung mit einem Github Repository. 1 Neben dem selbst trainierten de_fnhd_nerdh Modell, wurden dem Visualisierer auch die drei deutschen spaCy Sprachpakete implementiert. Somit kann ein Text mit vier verschiedenen NER-Modellen getestet und auf seine unterschiedlichen Ergebnisse hin verglichen werden. Zus\u00e4tzlich gibt es \u00fcber jedes Modell Informationen und eine \u00dcbersicht \u00fcber die Named Entities Typen. Das Modell de_fnhd_nerdh Es sollte klar sein, dass das selbst erstellte Modell de_fnhd_nerdh besonders gut mit Texten von Philipp Hainhofer funktioniert (F-Score 0.92), da es mit diesen trainiert wurden. Nur weil ein Text in fr\u00fchneuhochdeutsch geschrieben wurde, ist dies keine Garantie f\u00fcr ein gutes Ergebnis mit diesem Modell. Der Grund: Historische Texte sind zu spezifisch, als dass sie in einem Modell zusammengefasst werden k\u00f6nnten. Der zu analysierende Text kann einfach ins Textfeld reinkopiert werden oder aber - sofern im .txt-Format vorliegend - hochgeladen werden. Der NER-Prozess startet sobald der Text erfolgreich eingelesen wurde. Mittels der displacy -Funktion von spaCy werden die Named Entities visuell \u00fcbersichtlich dargestellt. Abgerundet wird der NerDH Visualisierer durch die Download-Funktion der NER-Ergebnisse. Der NerDH Visualisierer kann zum einen im Browser direkt besucht werden oder aber lokal auf dem Computer. Viel Spa\u00df damit! Browser Lokal Der NerDH Visualisierer wird nicht direkt mit streamlit gehostet, da die CPU und Speicherkapazit\u00e4ten der Streamlit Cloud f\u00fcr den NER-Prozess der vier Modelle nicht ausreichend ist. Daher wird der Visualisierer auf Hugging Face gehostet. Hugging Face Hugging Face ist eine Community- und Data-Science-Plattform, auf welcher Open-Source Projekte wie Machine-Learning Modelle, Datensets oder Web-App-Anwendungen frei publiziert werden k\u00f6nnen. Der Aufbau dazu ist \u00e4hnlich zu einem Github Repository. Streamlit Projekte k\u00f6nnen hier in sogenannten Spaces hochgeladen werden. 2 Hier geht es zum NerDH Visualisierer auf Hugging Face Falls der Visualisierer l\u00e4ngere Zeit nicht benutzt wurde, muss sich dieser erst wieder zusammenbauen. Das kann einen Moment dauern, da hier die Sprackpakete erneut heruntegeladen werden m\u00fcssen. An Running , Building und Stopped ist der aktuelle Status der App zu erkennen. Nachdem Restart Space gedr\u00fcckt wurde, sollte die Seite nach einer kurzen Zeit nochmal neu aktualisiert werden. NerDH Visualisierer in Browser Ansicht. Um die App lokal zu verwenden, muss das Github-Repository easyh/NerDH heruntergeladen werden. git clone https://github.com/easyh/NerDH.git Dann m\u00fcssen - sofern noch nicht im Tutorial gemacht -die entsprechenden Python-Pakete und die Sprachmodelle der requirements.txt lokal auf der Maschine installiert werden. Python Pakete und NER-Sprachmodelle installieren Befehle nacheinander ausf\u00fchren: pip install streamlit pip install spacy pip install spacy - streamlit pip install pandas NER-Modell de_history_md installieren: pip install https://huggingface.co/easyh/de_fnhd_nerdh/resolve/main/de_fnhd_nerdh-any-py3-none-any.whl Spacy NER-Modelle installieren: python - m spacy download de_core_news_sm python - m spacy download de_core_news_md python - m spacy download de_core_news_lg Speichergr\u00f6\u00dfe der Sprackpakete de_fnhd_nerdh : 586MB , de_core_news_sm: 13MB , de_core_news_md: 42MB , de_core_news_lg: 541MB` Jetzt muss nurnoch in den entsprechenden Ordner navigiert werden. cd nerdh_visualisierer Danach muss nurnoch folgender Befehl einmal ausgef\u00fchrt werden. streamlit run app.py Die App wird sich automatisch im Browser unter localhost \u00f6ffnen. Das kann einen kleinen Moment dauern. Das Ganze sollte dann in etwa so aussehen: NerDH Visualisierer in lokaler Ansicht. Die lokale Ansicht unterscheidet sich etwas zu der im Browser, da Hugging Face keine individuellen Desing-Anpassungen zul\u00e4sst. Streamlit. The fastest way to build and share data apps. (o. D.). https://streamlit.io/ \u21a9 Hugging Face. The AI community building the future. (o. D.). https://huggingface.co/ \u21a9","title":"NerDH-Visualisierer"},{"location":"gui/#nerdh-visualisierer","text":"Der Abschluss des Tutorials stellt der NerDH-Visualisierer dar. Er kommt mit einer einfachen und leicht zu bedienenden Benutzeroberfl\u00e4che, um einen Text schnell auf seine Named Entities zu untersuchen. Der Visualisierer wurde mit dem Open Source App Framework streamlit erstellt. Streamlit Streamlit konvertiert pythonbasierte Datenskripte zu Webanwendungen und hostet sie dabei kostenlos. M\u00f6glich ist dies durch die Verkn\u00fcpfung mit einem Github Repository. 1 Neben dem selbst trainierten de_fnhd_nerdh Modell, wurden dem Visualisierer auch die drei deutschen spaCy Sprachpakete implementiert. Somit kann ein Text mit vier verschiedenen NER-Modellen getestet und auf seine unterschiedlichen Ergebnisse hin verglichen werden. Zus\u00e4tzlich gibt es \u00fcber jedes Modell Informationen und eine \u00dcbersicht \u00fcber die Named Entities Typen. Das Modell de_fnhd_nerdh Es sollte klar sein, dass das selbst erstellte Modell de_fnhd_nerdh besonders gut mit Texten von Philipp Hainhofer funktioniert (F-Score 0.92), da es mit diesen trainiert wurden. Nur weil ein Text in fr\u00fchneuhochdeutsch geschrieben wurde, ist dies keine Garantie f\u00fcr ein gutes Ergebnis mit diesem Modell. Der Grund: Historische Texte sind zu spezifisch, als dass sie in einem Modell zusammengefasst werden k\u00f6nnten. Der zu analysierende Text kann einfach ins Textfeld reinkopiert werden oder aber - sofern im .txt-Format vorliegend - hochgeladen werden. Der NER-Prozess startet sobald der Text erfolgreich eingelesen wurde. Mittels der displacy -Funktion von spaCy werden die Named Entities visuell \u00fcbersichtlich dargestellt. Abgerundet wird der NerDH Visualisierer durch die Download-Funktion der NER-Ergebnisse. Der NerDH Visualisierer kann zum einen im Browser direkt besucht werden oder aber lokal auf dem Computer. Viel Spa\u00df damit! Browser Lokal Der NerDH Visualisierer wird nicht direkt mit streamlit gehostet, da die CPU und Speicherkapazit\u00e4ten der Streamlit Cloud f\u00fcr den NER-Prozess der vier Modelle nicht ausreichend ist. Daher wird der Visualisierer auf Hugging Face gehostet. Hugging Face Hugging Face ist eine Community- und Data-Science-Plattform, auf welcher Open-Source Projekte wie Machine-Learning Modelle, Datensets oder Web-App-Anwendungen frei publiziert werden k\u00f6nnen. Der Aufbau dazu ist \u00e4hnlich zu einem Github Repository. Streamlit Projekte k\u00f6nnen hier in sogenannten Spaces hochgeladen werden. 2 Hier geht es zum NerDH Visualisierer auf Hugging Face Falls der Visualisierer l\u00e4ngere Zeit nicht benutzt wurde, muss sich dieser erst wieder zusammenbauen. Das kann einen Moment dauern, da hier die Sprackpakete erneut heruntegeladen werden m\u00fcssen. An Running , Building und Stopped ist der aktuelle Status der App zu erkennen. Nachdem Restart Space gedr\u00fcckt wurde, sollte die Seite nach einer kurzen Zeit nochmal neu aktualisiert werden. NerDH Visualisierer in Browser Ansicht. Um die App lokal zu verwenden, muss das Github-Repository easyh/NerDH heruntergeladen werden. git clone https://github.com/easyh/NerDH.git Dann m\u00fcssen - sofern noch nicht im Tutorial gemacht -die entsprechenden Python-Pakete und die Sprachmodelle der requirements.txt lokal auf der Maschine installiert werden. Python Pakete und NER-Sprachmodelle installieren Befehle nacheinander ausf\u00fchren: pip install streamlit pip install spacy pip install spacy - streamlit pip install pandas NER-Modell de_history_md installieren: pip install https://huggingface.co/easyh/de_fnhd_nerdh/resolve/main/de_fnhd_nerdh-any-py3-none-any.whl Spacy NER-Modelle installieren: python - m spacy download de_core_news_sm python - m spacy download de_core_news_md python - m spacy download de_core_news_lg Speichergr\u00f6\u00dfe der Sprackpakete de_fnhd_nerdh : 586MB , de_core_news_sm: 13MB , de_core_news_md: 42MB , de_core_news_lg: 541MB` Jetzt muss nurnoch in den entsprechenden Ordner navigiert werden. cd nerdh_visualisierer Danach muss nurnoch folgender Befehl einmal ausgef\u00fchrt werden. streamlit run app.py Die App wird sich automatisch im Browser unter localhost \u00f6ffnen. Das kann einen kleinen Moment dauern. Das Ganze sollte dann in etwa so aussehen: NerDH Visualisierer in lokaler Ansicht. Die lokale Ansicht unterscheidet sich etwas zu der im Browser, da Hugging Face keine individuellen Desing-Anpassungen zul\u00e4sst. Streamlit. The fastest way to build and share data apps. (o. D.). https://streamlit.io/ \u21a9 Hugging Face. The AI community building the future. (o. D.). https://huggingface.co/ \u21a9","title":"NerDH Visualisierer"},{"location":"tut/","text":"NER Tutorial mit spaCy In dem Tutorial werden wir das Natural Language Processing (NLP) Tool spaCy n\u00e4her kennenlernen. Auch wenn spaCy im NLP Bereich mehr zu bieten hat als nur Named Entity Recogniton (NER), wird darauf der Fokus des Tutorials liegen. Starten werden wir mit einer allgemeinen Einf\u00fchrung in spaCy , in welcher wir die grundlegenden Funktionen f\u00fcr Textanalyseverfahren wie NER kennenlernen werden. Im zweiten Teil des Tutorials werden wir Schritt f\u00fcr Schritt lernen, wie man mit spaCy ein eigenes NER Modell trainiert. Als Trainingstext wird der Reisebericht M\u00fcnchen 1611 aus der digitalen Edition Philipp Hainhofer verwendet. Als Testtext M\u00fcnchen 1603 aus der Edition. Jupyter Notebooks In diesem Tutorial werden lediglich die Code Beispiele dargestellt. F\u00fcr die eigene Benutzung bieten sich folgende drei M\u00f6glichkeiten an: Github Repository Download Jupyter Notebook auf mybinder.org (durch die Verkn\u00fcpfung des Github Repositorys sind die interaktiven Notebooks direkt im Browser zu verwenden.) Kopieren des Codes in ein eigenes Dokument (Kopiersymbol in der rechten oberen Ecke). Github mybinder.org easyh/NerDH git clone https://github.com/easyh/NerDH.git Die Jupyter Notebooks sind im Ordner notebooks hinterlegt. Hier geht es zu allen Jupyter Notebooks auf mybinder.org Das Laden des Workspaces wird einen kurzen Moment in Anspruch nehmen. Viel Spa\u00df! 1. Einf\u00fchrung in spaCy Zun\u00e4chst wird die Bibliothek spaCy von der theoretischen Seite vorgestellt. Anschlie\u00dfend werden wir die Schritte zur Installation von spaCy und zum Herunterladen der vortrainierten Sprachmodelle durchgehen. 1.1 Was ist spaCy? spaCy ist ein leistungsstarkes Tool zur Verarbeitung nat\u00fcrlicher Sprache. Die NLP-Bibliothek f\u00fcr maschinelles Lernen wird seit 2016 von Explosion AI stetig weiterentwickelt und befindet sich mittlerweile in der dritten Version ( v.3.4.1 ). Das ist auch die Version, mit der wir hier im Tutorial arbeiten werden. Explosion AI ist ein Berliner Team aus Informatikern und Computerlinguisten. Die Software-Bibiliothek unterst\u00fctzt 70 europ\u00e4ische Sprachen mit statistischen Modellen, die in der Lage sind Texte zu parsen, Wortteile zu identifizieren und Entit\u00e4ten zu extrahieren. Zudem ist spaCy auch in der Lage, benutzerdefinierte Modelle auf dom\u00e4nenspezifsche Texte zu verbessern bzw. von Grund auf zu trainieren. F\u00fcr 24 von 70 unterst\u00fctzten insgesamt bietet spaCy bereits trainierte Pipelines mit unterschiedlichen Package-Gr\u00f6\u00dfen an. Weitere sind in Aussicht. 1 Leistungsumfang von spaCy Programming Language Python Neural network methods Neuronale Netze sind eine Reihe von Algorithmen. Sie interpretieren sensorische Daten durch eine Art maschinelle Wahrnehmung, indem sie den rohen Input kennzeichnen oder in Gruppen zusammenfassen. Die Muster, die sie erkennen, sind numerisch und in Vektoren enthalten. Link Integrated word vectors Die \u00c4hnlichkeit von W\u00f6rtern wird durch den Vergleich von Wortvektoren oder Worteinbettungen, mehrdimensionalen Bedeutungsdarstellungen eines Wortes, ermittelt. Wortvektoren k\u00f6nnen mit einem Algorithmus wie word2vec erzeugt werden Link Multi-language support Unterst\u00fctzt insgesamt 64 Sprachen und hat bereits trainierte Pipelines f\u00fcr 24 Sprachen. Link Tokenization Bei der Tokenisierung wird ein Text in Segemente wie W\u00f6rter oder Satzzeichen, so genannte Token, zerlegt. Die Eingabe f\u00fcr den Tokenizer ist ein Unicode-Text, und die Ausgabe ist ein Doc-Objekt. Link Part-of-Speech-Tagging Darunter versteht man die Zuordnung von W\u00f6rtern und Satzzeichen eines Textes zu Wortarten (engl. part of speech ). Hierzu wird sowohl die Definition des Wortes als auch der Kontext ber\u00fccksichtigt. Link Sentence segmentation Diese Aufgabe beinhaltet die Identifizierung von Satzgrenzen zwischen W\u00f6rtern in verschiedenen S\u00e4tzen. Link Lemmatization Lemmatisierung ist der Prozess der Gruppierung der gebeugten Formen eines Wortes, damit sie als ein einziges Element analysiert werden k\u00f6nnen, das durch das Lemma des Wortes oder die W\u00f6rterbuchform identifiziert wird Link Dependency Parsing Beim Dependency Parsing (DP) werden die Abh\u00e4ngigkeiten zwischen den W\u00f6rtern eines Satzes untersucht, um seine grammatische Struktur zu analysieren. Auf dieser Grundlage wird ein Satz in mehrere Komponenten zerlegt. Der Mechanismus basiert auf dem Konzept, dass es zwischen jeder sprachlichen Einheit eines Satzes eine direkte Verbindung gibt. Diese Verbindungen werden als Abh\u00e4ngigkeiten bezeichnet. Link Named Entity Recognition spaCy kann verschiedene Arten von benannten Entit\u00e4ten in einem Dokument erkennen, indem es das Modell um eine Vorhersage bittet. Da Modelle statistisch sind und stark von den Beispielen abh\u00e4ngen, mit denen sie trainiert wurden, funktioniert dies nicht immer perfekt und muss je nach Anwendungsfall m\u00f6glicherweise sp\u00e4ter angepasst werden. Link Named Entity Linking Um die benannten Entit\u00e4ten in der \"realen Welt\" zu verankern, bietet spaCy Funktionen f\u00fcr das Entity Linking, bei dem eine textuelle Entit\u00e4t in einen eindeutigen Identifikator aus einer Wissensbasis (KB) aufgel\u00f6st wird. Es kann eine eigene KnowledgeBase erstellt und einen neuen EntityLinker mit dieser Wissensbasis trainiert werden. Link Wie wir sehen, stellt Named Entity Recognition nur ein Bruchteil des Leistungsumfangs von spaCy dar. Daher ist ein Blick in die spaCy Dokumentation f\u00fcr weiterf\u00fchrende Informationen sehr empfehlenswert. Ebenfalls zu empfehlen ist das Tutorial von spaCy , welches den vollen Leistumgsumfang ber\u00fccksichtigt. 1.2 Installation spaCy Um spaCy zu installieren, muss nur Folgendes im Terminal eingeben werden 2 . pip install spacy Wenn spaCy vorher noch nie verwendet wurde, m\u00fcssen die Modelle/Pipelines noch heruntergeladen werden, damit wir mit diesen arbeiten k\u00f6nnen. Da wir NER mit deutschen Texten machen m\u00f6chten, sind f\u00fcr uns erstmal nur die deutschen Sprachmodelle von spaCy interessant. spaCy Deutsche Sprackpakete 3 Name Precision Recall F-Score NE-Typen Word-Vectors Gr\u00f6\u00dfe de_core_news_sm 0.83 0.82 0.82 LOC, MISC, ORG, PER 0 13MB de_core_news_md 0.85 0.84 0.84 LOC, MISC, ORG, PER 20.000 42MB de_core_news_lg 0.85 0.85 0.85 LOC, MISC, ORG, PER 300.000 541MB Es gibt zwar noch das Paket de_core_news_trf , allerdings enth\u00e4lt das Paket keine NER-Pipeline, sodass es f\u00fcr unsere Zwecke nicht relevant ist. Wie wir sehen, unterscheiden sich die Pakete besonders hinsichtlich ihrer Gr\u00f6\u00dfe. Verantwortlich daf\u00fcr ist die Anzahl der Word Vectors/Worteinbettungen . Eine h\u00f6here Anzahl von Word Vectors kann f\u00fcr die Ermittlung der Named Entites von Bedeutung sein. Mehr Infos zu den Sprachpaketen von spaCy gibt es hier . Precision, Recall, F-Score 4 Precision: Berechnet man, indem man die Zahl der richtig gefundenen Vorkommnisse einer Kategorie durch die Gesamtzahl der Markierungen einer Kategorie teilt\u200b. Wurden z.B. 100 Frauenfiguren im Text markiert, davon sind aber nur 97 richtig, so ist P 97:100=0,97 oder 97% . Recall: Berechnet man, indem man die Zahl der richtig gefundenen Vorkommnisse einer Kategorie durch die Gesamtzahl der tats\u00e4chlichen Vorkommnisse einer Kategorie teilt. Wurden z.B. 100 Frauenfiguren im Text richtig markiert, insgesamt gibt es aber 150 Ausdr\u00fccke, die Frauenfiguren bezeichnen, so ist R 100:150=0,66 oder 66% . F-Score: Kombiniert die Werte von Precision und Recall miteiander. Ein Wert nahe 1 bzw. 100% ist sehr gut. Die Sprachpakete k\u00f6nnen mit folgenden Befehlen heruntergeladen werden. python - m spacy download de_core_news_sm python - m spacy download de_core_news_md python - m spacy download de_core_news_lg Mit folgendem Befehl k\u00f6nnen wir uns unsere spaCy -Version sowie die bereits installierten Modelle/Pipelines anzeigen lassen. python -m spacy info 2. Erste Schritte mit spaCy Bevor wir nun mit der Erkennung von Named Entities und deren Visualisierung beginnen, lernen wir zun\u00e4chts ein paar grundlegende Objekte und Funktionen von spaCy kennen. Bis auf den ersten Codeteil sind die anderen NLP-Funktionen f\u00fcr unsere NER-Aufgabe nicht wichtig, sollen aber dennoch kurz vorgestellt werden, da sie wichtige Grundlagen f\u00fcr Textanalysen sind. Code Output #zuerst importieren wir spaCy import spacy #in der Variable text ist der Text gespeichert, der analysiert werden soll. text = \"Mia M\u00fcller wohnt in Trier und studiert an der Universit\u00e4t Trier. Aufgewachsen ist sie in M\u00fcnchen mit ihrem Bruder Tom.\" #Als n\u00e4chstes m\u00fcssen wir ein Modellobjekt laden. #Hierf\u00fcr verwenden wir die Funktion spacy.load(). #Diese nimmt ein Argument entgegen, n\u00e4mlich das Modell, das wir laden m\u00f6chten. #Wir werden das kleine deutsche Modell verwenden. nlp = spacy . load ( \"de_core_news_sm\" ) #Nachdem wir das nlp-Objekt erstellt haben, k\u00f6nnen wir es verwenden, um einen Text zu analysieren. #Zu diesem Zweck erstellen wir ein doc-Objekt. #Dieses Objekt wird eine Menge Daten \u00fcber den Text enthalten. doc = nlp ( text ) #Wir testen, ob das doc-Objekt unseren Text \u00fcbernommen hat. print ( doc ) Mia M\u00fcller wohnt in Trier und studiert an der Universit\u00e4t Trier. Aufgewachsen ist sie in M\u00fcnchen mit ihrem Bruder Tom. Sentence Tokenizer Code Output for sent in doc . sents : print ( sent ) Mia M\u00fcller wohnt in Trier und studiert an der Universit\u00e4t Trier. Aufgewachsen ist sie in M\u00fcnchen mit ihrem Bruder Tom. Part-of-Speech Tagging Code Output for token in doc : print ( token . text , token . pos_ ) Mia PROPN M\u00fcller PROPN wohnt VERB in ADP Trier PROPN und CCONJ studiert VERB an ADP der DET Universit\u00e4t NOUN Trier PROPN . PUNCT Aufgewachsen VERB ist AUX sie PRON in ADP M\u00fcnchen PROPN mit ADP ihrem DET Bruder NOUN Tom PROPN . PUNCT Erl\u00e4uterung der POS-Tags POS-Tag Erl\u00e4uterung PROPN Substantiv (Name einer Person) NOUN Substantiv VERB Verben ADJ Adjektiv ADV Adverb ADP Pr\u00e4-/Adpositionen DET Begleiter AUX Hilfsverb PUNCT Interpunktion CCONJ Konjunktion Substantive und Substantiv-Bausteine extrahieren Code Output for chunk in doc . noun_chunks : print ( chunk . text ) Mia Trier der Universit\u00e4t Trier sie M\u00fcnchen ihrem Bruder Tom Verben extrahieren Code Output #Verben sind im POS-TAg als \"VERB\" oder \"AUX\" definiert, daher iterieren wir f\u00fcr \u00fcber alle POS-TAGS, die \u00fcbereinstimmen. verbs = [ \"VERB\" , \"AUX\" ] for token in doc : if token . pos_ in verbs : print ( token . text , token . pos_ ) wohnt VERB studiert VERB Aufgewachsen VERB ist AUX Lemmatisierung Code Output for token in doc : print ( token . text , token . lemma_ ) Mia Mia M\u00fcller M\u00fcller wohnt wohnen in in Trier Trier und und studiert studieren an an der der Universit\u00e4t Universit\u00e4t Trier Trier . -- Aufgewachsen aufgewachsen ist sein sie sie in in M\u00fcnchen M\u00fcnchen mit mit ihrem ihr Bruder Bruder Tom Tom . -- 2.1 Entit\u00e4ten erkennen Der Code um Named Entities in einem Dokument zu erkennen ist \u00e4hnlich simpel wie der Code der anderen Funktionen. Wir iterieren erneut \u00fcber unser doc-Objekt mit der Funktion .ents . Code Output for ent in doc . ents : print ( ent . text , ent . label_ ) Mia M\u00fcller PER Trier LOC Universit\u00e4t Trier. ORG M\u00fcnchen LOC Tom. PER Wie wir sehen, hat das kleine Sprachmodell hier sehr gute Arbeit geleistet. Alle vorkommenden Named Entities wurden richtig erkannt. Sogar die zwei W\u00f6rter Universit\u00e4t und Trier wurden als ORGANISATION verstanden und nicht nur als ORT . Dieses Ph\u00e4nomen wird auch als Nested Entities bezeichnet, weil in einer Entit\u00e4t gleich mehrere stecken k\u00f6nnen. Um beispielsweise nur die benannten Entit\u00e4ten zu extrahieren, die beispielsweise als PERSON identifiziert wurden, k\u00f6nnen wir eine einfache if-Anweisung in den Mix einf\u00fcgen. Code Output for ent in doc . ents : if ent . label_ == \"PER\" : print ( ent ) Mia M\u00fcller Tom. Wir k\u00f6nnen uns zus\u00e4tzlich noch ausgeben lassen, an welcher Stelle im Text die Named Entities zu finden sind. Code Output for ent in doc . ents : print ( ent . text , ent , start_char , ent . end_char , ent . label_ ) Mia M\u00fcller 0 10 PER Trier 20 25 LOC Universit\u00e4t Trier. 46 64 ORG M\u00fcnchen 89 96 LOC Tom. 114 118 PER 2.2 NER visualisieren spaCy hat eine eingebaute Funktion zur Visualisierung der Entit\u00e4ten namens displacy . Der schnellste Weg, ein doc-Objekt zu visualisieren ist displacy.serve . Dadurch wird ein einfacher Webserver gestartet und das Ergebnis kann im Browser betrachtet werden. Da wir innerhalb eines Jupyter Notebooks arbeiten, verwenden wir die Funktion displacy.render . Zun\u00e4chst m\u00fcssen wir dazu noch displacy importieren. Code Output from spacy import displacy displacy . render ( doc , style = \"ent\" ) Mia M\u00fcller PER wohnt in Trier LOC und studiert an der Universit\u00e4t Trier. ORG Aufgewachsen ist sie in M\u00fcnchen LOC mit ihrem Bruder Tom. PER Hier k\u00f6nnen wir jetzt noch eigene Anpassungen wie die Auswahl der Entit\u00e4ten, als auch die Farbe ausf\u00fchren. Die individuellen Farben geben wir f\u00fcr alle vier Entit\u00e4tstypen an, allerdings wollen wir uns hier nur die Personen ( PER ) und Orte ( LOC ) ausgeben lassen. Code Output colors = { \"PER\" : \"#fdec3e\" , \"LOC\" : \"#7e56c2\" , \"ORG\" : \"#209485\" , \"MISC\" : \"#eb4034\" } options = { \"ents\" : [ \"PER\" , \"LOC\" ], \"colors\" : colors } displacy . render ( doc , style = \"ent\" , options = options ) Mia M\u00fcller PER wohnt in Trier LOC und studiert an der Universit\u00e4t Trier. Aufgewachsen ist sie in M\u00fcnchen LOC mit ihrem Bruder Tom. PER Jupyter Notebooks Der Code zu diesem Kapitel befindet sich hier: notebooks/01_firstSteps_spacy.ipynb . Github mybinder.org Hier geht es zum Notebook auf Github Hier geht es zum Jupyter Notebook auf mybinder.org Das Laden des Workspaces wird einen kurzen Moment in Anspruch nehmen. 3. Eigenes Modell trainieren mit spaCy Je nach Anwendungsfall macht es wenig Sinn nur mit dem Standardmodell zu arbeiten. Weshalb es besser ist, ein neues Modell zu trainieren bzw. auf ein bestehendes aufzubauen. Besonders bei historischen Texten entstehen Probleme und Schwierigkeiten aufgrund ihrer Heterogenit\u00e4t. NER mit fnhd. Text Folgendes Beispiel zeigt, wie das kleine spaCy Sprachmodell mit einem Satz aus dem fr\u00fchneuhochdeutschen abschneidet. Der Satz ist aus unserem Traningstext M\u00fcnchen 1611 von Philipp Hainhofer. Code Output text_fnhd = \"Aines m\u00f6rders Conterfett, genant Christoff Froschhammer von Vlingingen, der Hat 345 m\u00f6rd, mit seiner aignen hand, vnd 400 mord in gesellschafft anderer, gethan, ist Anno 1578 zu Wel\u00df in Ste\u00ffrmarck gerichtet worden, vnd au\u00df dem stifft Saltzburg geb\u00fcrtig gewesen.\" nlp = spacy . load ( \"de_core_news_sm\" ) doc_fnhd = nlp ( text_fnhd ) for ent in doc_fnhd . ents : print ( ent . text , ent . label_ ) Aines m\u00f6rders MISC Christoff Froschhammer PER Anno LOC Wel\u00df PER Ste\u00ffrmarck MISC Saltzburg LOC Wie wir sehen wurden nur zwei Entit\u00e4ten richtig erkannt: Christoff Froschhammer als PERSON und Saltzburg als ORT . Vlingingen , sowie Wel\u00df und Ste\u00ffrmarck wurden nicht richtig oder garnicht als ORT erkannt. Zudem hat das Modell Entit\u00e4ten erkannt, die eigentlich keine Entit\u00e4ten sind: Anno und Aines m\u00f6rder . Vor dem Training eines eigenen NER-Modells ist es wichtig, folgende drei Fragen zu kl\u00e4ren: Was sind die Daten? Unsere Daten entstammen der digitalen Edition Philipp Hainhofer . Hier haben wir uns f\u00fcr den Reisebericht M\u00fcnchen 1611 als Trainingstext und M\u00fcnchen 1603 als Testtext entschieden. Die Texte der Edition stehen in TEI-XML , PDF sowie TXT zum Download verf\u00fcgbar. Wir verwenden die Daten im TXT -Format, denn einige Studien haben gezeigt, dass eine umfangreiche XML-Annotation, die dem NER-Prozess vorausgeht, die Leistung beeintr\u00e4chtigen kann. NER-Systeme sollten daher idealerweise angewendet werden, bevor ein Korpus mit Standards wie TEI annotiert wird. In dieser Reihenfolge k\u00f6nnen die NER-Ergebnisse dann auch bei der TEI-Codierung sehr hilfreich sein. Welche Entit\u00e4ten m\u00f6chte ich ausw\u00e4hlen? Hier geht es darum, die relevanten Kategorien und Entit\u00e4ten auszuw\u00e4hlen. Daf\u00fcr ist es wichtig zu wissen, welche und wie viele NE-Katogorien man f\u00fcr die jeweiligen Texte verwenden will. In unserem Modell werden wir die folgenden Entit\u00e4ten trainieren: Named Entities Beschreibung PERSON Einzelperson oder Familie ORT Geographische Einheit, d. h. L\u00e4nder, St\u00e4dte, Staaten, Fl\u00fcsse ORGANISATION Institutionen,(Ordens-)Gemeinschaften, Verbindungen, etc. OBJEKT Architektur, Geb\u00e4ude, Kunst, Werke etc. ZEIT Datum, Monat, Jahr, Uhrzeit etc. Wie m\u00f6chte ich diese Entit\u00e4ten kennzeichen? Hier geht es darum, wie die Entit\u00e4ten annotiert werden. Dabei sollte sich auf eine einheitliche Annotationskonvention beschr\u00e4nkt werden. Das Ergebnis sollte am ein Ende ein Goldstandard sein, anhand dessen sp\u00e4ter das NER-Modell bewertet wird, indem die per Hand angefertigen Annotationen mit der Ausgabe des NER-Systems verglichen werden. Im Laufe dieses Kapitels werden wir lernen, wie das Training eines eigenen Modells mit spaCy umgesetzt wird. Unser Workflow f\u00fcr das Training eines eigenen NER-Modells sieht wie folgt aus: Workflow: Training eines eigenen NER Modells 3.1 Preprocessing Bevor wir mit dem Trainings- und dem anschlie\u00dfenden Evaluierungsprozess starten, m\u00fcssen wir zun\u00e4chst einen Goldstandard erstellen und diesen dann in Trainings-, Validierungs- & Testdaten aufteilen. Dieser Schritt geh\u00f6rt zum sogennanten Preprocessing des maschinellen Lernens. Vor der Annotation des Goldstandards, sollten wir unsere beiden Texte allerdings noch etwas kennenlernen und vorbereiten. Auf die n\u00e4here Ausf\u00fchrung soll an dieser Stelle verzichtet werden, allerdings ist alles wichtige zu diesem Schritt im Notebook 02_preprocessingText.ipynb festgehalten. Jupyter Notebooks Der Code zu diesem Kapitel befindet sich hier: notebooks/02_preprocessingText.ipynb . Github mybinder.org Hier geht es zum Notebook auf Github Hier geht es zum Jupyter Notebook auf mybinder.org Das Laden des Workspaces wird einen kurzen Moment in Anspruch nehmen. 3.1.1 Annotation eines Goldstandards Die Annotation des Goldstandrds ist der erste wichtige Schritt, um ein Trainingskorpus zu erstellen. Goldstandard Ein Goldstandard ist eine manuelle Referenz-Annotation, bei der die relevanten Named Entities annotiert werden. Es ist die finale Version der annotierten Daten, die f\u00fcr den Trainingsprozess verwendet werden. Je besser und genauer die Auszeichnungen f\u00fcr den Goldstandard gemacht werden, desto besser ist das Trainingsergebnis. Anhand des Goldstandards, kann sp\u00e4ter die Qualit\u00e4t eines NER-Modell bewertet werden, quantifziert als Recall, Precision und F-Score. Es gibt mehrere M\u00f6glichkeiten Texte so zu annotieren, dass sie maschinenlesbar sind. Hier muss je nach Anwendungsbereich entschieden werden, welcher Annotationsstandard der passendste ist. In den Digital Humanities werden die meisten Texte mithilfe der auf XML basierenden Anwendung der Text Encoding Initiative (TEI) annotiert. Ein anderer bekannter Standard zum Annotieren von Named Entities ist das IOB-Schema (bzw. BIO-Schema). Da wir allerdings ein NER-Modell mit spaCy trainieren wollen, m\u00fcssen wir unseren Goldstandard entsprechend f\u00fcr die Software anpassen. spaCy verlangt ein spezielles Traningsformat, in welchem die Daten vorliegen m\u00fcssen. Das Beispiel zeigt das klassische Format: TRAIN_DATA = [\"TEXT AS A STRING\",{\"entities:\"[(START,END,LABEL)]}] Es gibt zahlreiche Auszeichnungstools, die f\u00fcr Anwendungen des maschinellen Lernens entwickelt wurden und bei der Annotation von Texten helfen. Darunter auch einige, welche die Daten direkt in das entsprechende Trainingsformat f\u00fcr spaCy bringen. Daf\u00fcr wurde speziell prodigy entwickelt, was allerdings kostenpflichtig ist. Aber es gibt auch einige Open-Source-Programme, die eine gute Alternative darstellen. Wir haben unseren Goldstandard mit dem NER-Annotator erstellt. Hier kann ein Text im TXT -Format importiert, annotiert und dann anschlie\u00dfend im JSON -Format exportiert werden. Die JSON -Datei enth\u00e4lt dann die annotierten Daten, die in dem f\u00fcr spaCy geeigneten Format vorliegen. Allerdings m\u00fcssen die JSON -Dateien f\u00fcr den Trainingsprozess nochmal in .spacy -Dateien umgewandelt werden. Der NER-Annotator stellt hier Code zur Verf\u00fcgung (n\u00e4heres dazu im n\u00e4chsten Kapitel zur Erstellung der Datensets). Das folgende Bild zeigt, wie die Annotation erfolgt. In der oberen Zeile k\u00f6nnen die Entit\u00e4ten Kategorien festgelegt werden. Ist eine Kategorie mit einem Haken markiert (hier ORT ) kann im Text damit die entsprechende Entit\u00e4t markiert werden. So arbeiten wir uns St\u00fcck f\u00fcr St\u00fcck durch unseren Text, bis wir fertig sind. Enth\u00e4lt ein Satz keine Entit\u00e4ten, dann \u00fcberspringen ( skip ) wir diesen. In unserer Datei sind sp\u00e4ter nur S\u00e4tze enthalten, die Entit\u00e4ten enthalten. Erstellung des Goldstandards f\u00fcr das Training mit dem NER-Annotator-for-spaCy. In der JSON -Datei ist dieser Satz dann im folgenden Format wieder zu finden: { \"classes\" : [ \"PERSON\" , \"ORT\" , \"ORGANISATION\" , \"OBJEKT\" , \"ZEIT\" ], \"annotations\" : [[ \"Aines m\u00f6rders Conterfett, genant Christoff Froschhammer von Vlingingen, der Hat 345 m\u00f6rd, mit seiner aignen hand, vnd 400 mord in gesellschafft anderer, gethan, ist Anno 1578 zu Wel\u00df in Ste\u00ffrmarck gerichtet worden, vnd au\u00df dem stifft Saltzburg geb\u00fcrtig gewesen.\" , { \"entities\" : [[ 33 , 55 , \"PERSON\" ],[ 60 , 70 , \"ORT\" ],[ 165 , 174 , \"ZEIT\" ],[ 178 , 182 , \"ORT\" ],[ 186 , 196 , \"ORT\" ],[ 234 , 243 , \"ORT\" ]]}]]} Der Prozess des Annotieren kann je nach L\u00e4nge des Textes sehr aufw\u00e4ndig und anstrengend sein. Bei sehr langen Texten bietet es sich an, den Text in einzelene Dateien zu unterteilen, um dann in Etappen die Annotation durchzuf\u00fchren. Am Ende k\u00f6nnen die einzelnen JSON -Dateien, dann wieder zu einer Datei zusammengef\u00fcgt werden, die dann den finalen Goldstandard darstellt. Die folgende Tabelle soll einen kurzen \u00dcberblick \u00fcber den Trainingstext M\u00fcnchen 1611 und den Testtext M\u00fcnchen 1603 und dessen annotierten Enitit\u00e4ten geben. Text S\u00e4tze Tokens/W\u00f6rter Zeichen PERSON ORT ORG OBJEKT ZEIT Gesamt Entit\u00e4ten M\u00fcnchen 1611 1 595 41 087 225 952 1019 840 63 238 451 2611 M\u00fcnchen 1603 147 5 928 31 747 54 55 16 53 22 200 GESAMT 1 742 47 015 257 699 1073 895 79 291 473 2811 Der Goldstandard f\u00fcr den Traningstext befindet sich hier ( data/datensets/taggedData.json ). 3.1.2 Training-, Validierung- und Testdaten Beim maschinellen Lernen ben\u00f6tigen wir einen Trainingsdatensatz, um ein Modell richtig zu trainieren und einen Testdatensatz, um das Modell zu bewerten. Der Datensatz taggedData.json umfasst den komplett annotierten Text M\u00fcnchen 1611 . Bei \u00fcberwachten Lernmethoden wird dieser Datensatz in der Regel in mindestens drei verschiedene Datens\u00e4tze unterteilt: Training-, Validierung- und Testdaten . In unserem Fall \u00fcbernehmen die Trainingsdaten ( testData.json ) bei uns die annotierten Daten aus dem Text M\u00fcnchen 1603 . \u00dcberwachtes Lernen In unserem Fall arbeiten wir mit der \u00fcberwachten Lernmethode , bei der Beispieldaten in Form eines annotierten Goldtstandards notwendig sind, damit der Algoritmus lernen kann. Bei un\u00fcberwachten Lernmethode hingegen br\u00e4uchten wir keine Beispiele, da hier direkt mit den Eingabedaten trainiert wird und der Algorithmus hier von selbst Muster und Zusammenh\u00e4nge lernen w\u00fcrde. Die Aufteilung unsrer Daten sieht wie folgt aus. Den Datensatz taggedData.json werden wir noch in Trainingsdaten und Validierungsdaten einteilen m\u00fcssen. Aufteilung in Training-, Validierung- und Testdaten. Training-, Validierung- und Testdaten 5 Datensatz Anteil Erkl\u00e4rung Traningsdaten 70% Ein Trainingsdatensatz ist eine Sammlung von Beispielen, die verwendet werden, um einem Algorithmus beizubringen, Muster und Zusammenh\u00e4nge in den Daten zu erkennen. Der Algorithmus passt seine Gewichte anhand der Trainingsdaten an, indem er aus ihnen lernt. Trainingsdaten werden f\u00fcr Klassifikations- und Regressionsprobleme ben\u00f6tigt, bei denen es darum geht, Vorhersagen f\u00fcr bestimmte Zielvariablen zu treffen. Es kann vorkommen, dass Algorithmen, die auf Trainingsdaten lernen, zu sehr auf die Muster in diesen Daten angepasst werden und somit nicht gut auf neue, noch nicht gesehene Daten anwendbar sind. Dies wird als \"\u00dcberanpassung\" oder \"Overfitting\" bezeichnet. Das bedeutet, dass der Algorithmus zu starke Regeln aus den Trainingsdaten lernt, die auf die Gesamtheit der Daten nicht gut anwendbar sind. Validierungsdaten 20% Der Validierungsdatensatz ist eine Sammlung von Beispieldaten, die verwendet werden, um die Hyperparameter eines Modells anzupassen. Hyperparameter sind Einstellungen, die vor dem Training festgelegt werden und Einfluss auf das Lernverhalten des Modells haben. Beispiele f\u00fcr Hyperparameter bei k\u00fcnstlichen neuronalen Netzen sind die Anzahl der Neuronen in jeder Schicht oder die Lernrate. Durch die Verwendung von Validierungsdaten beim Training kann verhindert werden, dass das Modell zu sehr auf die Trainingsdaten angepasst wird und somit auf neue, noch nicht gesehene Daten nicht gut anwendbar ist. Testdaten 10% Die Testdaten sind von den Trainingsdaten unabh\u00e4ngig und werden w\u00e4hrend des Trainingsprozesses nicht verwendet. Sie dienen dazu, das trainierte Modell zu bewerten und zu \u00fcberpr\u00fcfen, wie gut es auf neue, noch nicht gesehene Daten anwendbar ist. Die Testdaten sollten dieselbe Wahrscheinlichkeitsverteilung wie der Trainingsdatensatz aufweisen. Wenn das Modell gut auf die Testdaten anwendbar ist, kann es vermutlich auch auf andere, bisher ungesehene Daten angewendet werden. Um jetzt unseren gro\u00dfen Datensatz taggedData.json in zwei Datensets aufzuteilen, lesen wir diesen zun\u00e4chts ein und speichern nur die Eintr\u00e4ge von annotations in der Variablen TAGGED_DATA , damit wir die Eintr\u00e4ge z\u00e4hlen k\u00f6nnen. Danach ermitteln wir die Grenze (80:20), damit wir den ursp\u00fcnglichen Datensatz in kleinere Datens\u00e4tze zu je 80% und 20%. Code Output import json f = open ( '../data/datensets/taggedData.json' ) data = json . load ( f ) TAGGED_DATA = data [ 'annotations' ] print ( len ( TAGGED_DATA ) * 0.8 ) 696.8000000000001 Bevor wir den Datensatz an der ermittelten Grenzen in die zwei Datensets aufteilen, mischen wir die Eintr\u00e4ge noch einmal durch, damit die Verteilung zuf\u00e4llig ist. Hier lassen wir uns dann jeweils die L\u00e4nge ausgeben, um das Ergebnis zu \u00fcberpr\u00fcfen. Zus\u00e4tzlich lassen wir uns auch noch die Gr\u00f6\u00dfe des Testdatensatz ausgeben, um zu \u00fcberpr\u00fcfen, ob die 70:20:10 Verteilung ungef\u00e4hr hinhaut. Code Output import random random . shuffle ( TAGGED_DATA ) train_data = TAGGED_DATA [: 697 ] val_data = TAGGED_DATA [ 697 :] print ( \"Traningsdaten: \" + str ( len ( train_data ))) print ( \"Validierungsdaten: \" + str ( len ( val_data ))) #Zum vergleich, lassen wir uns auch die G\u00f6\u00dfe von unseren Testdaten ausgeben f = open ( '../data/datensets/testData.json' ) data = json . load ( f ) test_data = data [ 'annotations' ] print ( \"Testdaten: \" + str ( len ( test_data ))) Traningsdaten: 697 Validierungsdaten: 174 Testdaten: 87 Anschlie\u00dfend speichern wir die Datensets im JSON -Format ab. Code with open ( '../data/datensets/trainData.json' , 'w' , encoding = 'utf-8' ) as train : json . dump ( train_data , train , ensure_ascii = False , indent = 4 ) with open ( '../data/datensets/valuationData.json' , 'w' , encoding = 'utf-8' ) as val : json . dump ( val_data , val , ensure_ascii = False , indent = 4 ) Da wir weiter oben nur die Eintr\u00e4ge aus annotations der JSON-Datei \u00fcbernommen haben, m\u00fcssen wir jetzt noch einmal manuell bei trainData.json sowie validationData.json die classes hinzuf\u00fcgen, damit unsere Kategorien f\u00fcr die Entit\u00e4ten nicht verloren gehen. Dazu setzen wir an den Anfang des Dokuments folgendes und ans Ende eine } um das Dokument zu schlie\u00dfen. { \"classes\" : [ \"PERSON\" , \"ORT\" , \"ORGANISATION\" , \"OBJEKT\" , \"ZEIT\" ], \"annotations\" : Jetzt m\u00fcssen die Datensets im JSON -Format nurnoch ins spaCy -Format konvertiert werden. Daf\u00fcr importieren wir zun\u00e4chst die ensprechenden Bibliotheken und das mittlere Sprachmodell von spaCy . Code import spacy from spacy.tokens import DocBin from tqdm import tqdm #neues spacy Model laden nlp = spacy . load ( \"de_core_news_md\" ) #DocBin Objekt erstellen db = DocBin () Jetzt m\u00fcssen wir f\u00fcr jedes Datenset nur noch folgenden Code ausf\u00fchren, welcher uns vom NER-Annotator vorgegeben wird, damit die Datensets im spaCy -Datenformat sind. Traningsdaten Validierungsdaten Testdaten f = open ( '../data/datensets/trainData.json' ) TRAIN_DATA = json . load ( f ) for text , annot in tqdm ( TRAIN_DATA [ 'annotations' ]): doc = nlp . make_doc ( text ) ents = [] for start , end , label in annot [ \"entities\" ]: span = doc . char_span ( start , end , label = label , alignment_mode = \"contract\" ) if span is None : print ( \"Skipping entity\" ) else : ents . append ( span ) doc . ents = ents db . add ( doc ) #Docbin Objekt speichern db . to_disk ( \"../data/datasets/trainData.spacy\" ) f = open ( '../data/datensets/valuationData.json' ) VAL_DATA = json . load ( f ) for text , annot in tqdm ( VAL_DATA [ 'annotations' ]): doc = nlp . make_doc ( text ) ents = [] for start , end , label in annot [ \"entities\" ]: span = doc . char_span ( start , end , label = label , alignment_mode = \"contract\" ) if span is None : print ( \"Skipping entity\" ) else : ents . append ( span ) doc . ents = ents db . add ( doc ) #Docbin Objekt speichern db . to_disk ( \"../data/datasets/valuationData.spacy\" ) f = open ( '../data/datensets/testData.json' ) TEST_DATA = json . load ( f ) for text , annot in tqdm ( TEST_DATA [ 'annotations' ]): doc = nlp . make_doc ( text ) ents = [] for start , end , label in annot [ \"entities\" ]: span = doc . char_span ( start , end , label = label , alignment_mode = \"contract\" ) if span is None : print ( \"Skipping entity\" ) else : ents . append ( span ) doc . ents = ents db . add ( doc ) #Docbin Objekt speichern db . to_disk ( \"../data/datasets/testData.spacy\" ) Damit ist das Preprocessing abgeschlossen und wir k\u00f6nnen mit dem Training des Modells beginnen. Jupyter Notebooks Der Code zu diesem Kapitel befindet sich hier: notebooks/03_createDatasets_spacy.ipynb . Github mybinder.org Hier geht es zum Notebook auf Github Hier geht es zum Jupyter Notebook auf mybinder.org Das Laden des Workspaces wird einen kurzen Moment in Anspruch nehmen. 3.3 Training Da wir jetzt alle unsere Daten haben, ist es an der Zeit unser Modell zu trainieren. In spaCy k\u00f6nnen wir die Architektur unserer Netzes sowie die Hyperparamter f\u00fcr unser Modell weitgehend steuern. Dies geschieht in der config.cfg Datei. Diese Konfigurationsdatei wird spaCy w\u00e4hrend dem Trainingsprozess \u00fcbergeben, damit das System wei\u00df, was und wie es trainieren soll. Um die config.cfg Datei zu erstellen, k\u00f6nnen wir die praktische GUI von spaCy selbst benutzen. F\u00fcr unsere Zwecke w\u00e4hlen wir German , ner und CPU (GPU ist etwas komplexer). Jenachdem ob wir ohne Wortvektoren oder mit ihnen trainieren wollen, w\u00e4hlen wir efficiency oder accuracy . In unserem Beispiel haben wir mit accuracy , also mit Wortvektoren trainiert. Hier werden dann die Vektoren des gro\u00dfen deutschen Modell de_core_news_lg \u00fcbernommen (das k\u00f6nnen wir nat\u00fcrlich auch mit dem kleinen bzw. mittleren Modell machen). Diese Datei speichern wir zun\u00e4chst als base_config.cfg ab. Die base_config.cfg -Datei befindet sich ebenfalls auf Github im Ordner notebooks oder kann hier einfach kopiert werden. base_config.cfg [paths] train = null dev = null vectors = \"de_core_news_lg\" [system] gpu_allocator = null [nlp] lang = \"de\" pipeline = [\"tok2vec\",\"ner\"] batch_size = 1000 [components] [components.tok2vec] factory = \"tok2vec\" [components.tok2vec.model] @architectures = \"spacy.Tok2Vec.v2\" [components.tok2vec.model.embed] @architectures = \"spacy.MultiHashEmbed.v2\" width = ${components.tok2vec.model.encode.width} attrs = [\"NORM\", \"PREFIX\", \"SUFFIX\", \"SHAPE\"] rows = [5000, 1000, 2500, 2500] include_static_vectors = true [components.tok2vec.model.encode] @architectures = \"spacy.MaxoutWindowEncoder.v2\" width = 256 depth = 8 window_size = 1 maxout_pieces = 3 [components.ner] factory = \"ner\" [components.ner.model] @architectures = \"spacy.TransitionBasedParser.v2\" state_type = \"ner\" extra_state_tokens = false hidden_width = 64 maxout_pieces = 2 use_upper = true nO = null [components.ner.model.tok2vec] @architectures = \"spacy.Tok2VecListener.v1\" width = ${components.tok2vec.model.encode.width} [corpora] [corpora.train] @readers = \"spacy.Corpus.v1\" path = ${paths.train} max_length = 0 [corpora.dev] @readers = \"spacy.Corpus.v1\" path = ${paths.dev} max_length = 0 [training] dev_corpus = \"corpora.dev\" train_corpus = \"corpora.train\" [training.optimizer] @optimizers = \"Adam.v1\" [training.batcher] @batchers = \"spacy.batch_by_words.v1\" discard_oversize = false tolerance = 0.2 [training.batcher.size] @schedules = \"compounding.v1\" start = 100 stop = 1000 compound = 1.001 [initialize] vectors = ${paths.vectors} Da die base_config.cfg -Datei nun korrekt eingerichtet ist, m\u00fcssen wir sie in eine config.cfg -Datei umwandeln. Dazu m\u00fcssen wir einen Terminalbefehl ausf\u00fchren. Durch Ausf\u00fchren des folgenden Befehls erhalten wir die korrekt formatierte config.cfg -Datei. python -m spacy init fill-config ./base_config.cfg ./config.cfg Jetzt haben wir alles, um unser erstes Modell zu trainieren. Wir erstellen einen Ordner namens output , hier wird unser fertiges Modell dann abgelegt. Wir m\u00fcssen nur den folgenden Befehl ausf\u00fchren, etwas warten und schon haben wir ein trainiertes Modell. Hinter paths.train setzen wir den Pfad zu unseren Trainingsdaten und hinter paths.dev unsere Valuierungsdaten python -m spacy train config.cfg --output ./output --paths.train ./datensets/trainData.spacy --paths.dev ./datensets/valuationData.spacy Trainingsausgabe Die Ausgabe zeigt uns die Epochen, die Anzahl der Stichproben sowie einige Metriken f\u00fcr unser Modell. \u2139 Saving to output directory: output \u2139 Using CPU =========================== Initializing pipeline =========================== [2022-11-19 13:23:54,923] [INFO] Set up nlp object from config [2022-11-19 13:23:54,941] [INFO] Pipeline: ['tok2vec', 'ner'] [2022-11-19 13:23:54,949] [INFO] Created vocabulary [2022-11-19 13:24:00,463] [INFO] Added vectors: de_core_news_lg [2022-11-19 13:24:06,491] [INFO] Finished initializing nlp object [2022-11-19 13:24:09,274] [INFO] Initialized pipeline components: ['tok2vec', 'ner'] \u2714 Initialized pipeline ============================= Training pipeline ============================= \u2139 Pipeline: ['tok2vec', 'ner'] \u2139 Initial learn rate: 0.001 E # LOSS TOK2VEC LOSS NER ENTS_F ENTS_P ENTS_R SCORE --- ------ ------------ -------- ------ ------ ------ ------ 0 0 0.00 85.09 0.00 0.00 0.00 0.00 0 200 880.61 2879.21 55.96 75.37 44.50 0.56 1 400 65.55 1510.84 71.81 67.93 76.15 0.72 2 600 109.01 1268.59 82.27 81.65 82.89 0.82 4 800 78.71 901.58 86.86 87.08 86.64 0.87 5 1000 74.96 737.24 88.99 91.39 86.73 0.89 7 1200 80.31 559.43 90.62 91.06 90.18 0.91 show more (open the raw output data in a text editor) ... 143 5200 180.50 58.97 93.98 93.86 94.10 0.94 151 5400 211.91 75.53 93.96 93.79 94.14 0.94 159 5600 376.93 128.75 94.00 93.98 94.02 0.94 \u2714 Saved pipeline to output directory output/model-last In unserem output -Ordner befinden sich nun zwei Unterordner: model-best und model-last . Beide dieser Modelle k\u00f6nnen jetzt in der spacy.load() Funktion eingelesen und ausprobiert werden. Hier wird dann einfach der Pfad angegeben, wo das Modell liegt. import spacy nlp = spacy . load ( output / model - best ) Im Github Repositry gibt es keinen output -Ordner mit einem Modell, da das trainierte Modell zu gro\u00df ist. Allerdings gibt es von spaCy die M\u00f6glichkeit ein Modell in ein Python Package zu packen, dass dann wie jedes andere Package mit pip install installiert werden kann. Modell als Python Package verpacken Daf\u00fcr m\u00fcssen wir uns einmal in das innere unseres Modells klicken und in der meta.json -Datei noch kleine \u00c4nderungen machen. Bei name vergeben wir dem Modell einen Namen, mit dem wir es laden m\u00f6chten. Zus\u00e4tzlich geben wir noch eine version an: Da es unser erstes Modell ist setzen wir die Version auf 0.0.1 . Nat\u00fcrlich k\u00f6nnen wir hier auch noch mehr Informationen wie z.B. description , author oder email angeben. { \"lang\" : \"de\" , \"name\" : \"de_fnhd_nerdh\" , \"version\" : \"0.0.1\" , \"spacy_version\" : \">=3.4.1,<3.5.0\" , \"description\" : \"\" , \"author\" : \"\" , \"email\" : \"\" , ... } Dann erstellen wir einen Ordner package , hier wird unser verpacktes Modell gespeichert, und geben folgenden Terminalbefehl ein: python -m spacy package ./output/model-best ./package --build wheel Lokal k\u00f6nnen wir unser Modell jetzt installieren einfach wie folgt installieren. Wir m\u00fcssen uns hierf\u00fcr allerdings im Verzeichnis dist befinden oder dorthin navigieren: pip install package/de_fnhd_nerdh-0.0.1/dist/de_fnhd_nerdh-0.0.1-py3-none-any.whl Jetzt k\u00f6nnen wir unser selbst erstelltes Modell wie die spaCy Modelle benutzen. import spacy nlp = spacy . load ( de_fnhd_nerdh ) Modellpackage ver\u00f6ffentlichen Mithilfe von spacy-huggingface-hub k\u00f6nnen wir unser verpacktes Modell ver\u00f6ffentlichen und anderen Usern anbieten. Dazu m\u00fcssen wir uns vorher einen Account auf huggingface.co erstellen und das Package installieren. pip install spacy-huggingface-hub Jetzt k\u00f6nnen wir uns \u00fcber den Terminal in huggingface.co einloggen, damit unser Package unserem Profil zugeordnet wird. Hier werden wir nach einem Token gefragt, den wir hier abrufen k\u00f6nnen. huggingface-cli login Mit folgendem Befehl pushen wir unser Projekt auf huggingface.co . python -m spacy huggingface-hub push package/de_fnhd_nerdh-0.0.1/dist/de_fnhd_nerdh-0.0.1-py3-none-any.whl Der Befehl wird dann zwei Dinge ausgeben: wo das Repository auf huggingface.co gefunden wird Link, mit welchem das Modell installiert werden kann Das Modell, welches hier im Tutorial erstellt wurde kann mit diesem Befehl als Python Package installiert werden. pip install https://huggingface.co/easyh/de_fnhd_nerdh/resolve/main/de_fnhd_nerdh-any-py3-none-any.whl Jupyter Notebooks Der Code zu diesem Kapitel befindet sich hier: notebooks/04_trainEvaluateModel_spacy.ipynb . Github mybinder.org Hier geht es zum Notebook auf Github Hier geht es zum Jupyter Notebook auf mybinder.org Das Laden des Workspaces wird einen kurzen Moment in Anspruch nehmen. 3.4 Evaluierung Der n\u00e4chste logische Schritt ist jetzt nat\u00fcrlich die Evaluation unseres Modells. Hierf\u00fcr ben\u00f6tigen wir unsere Testdaten. Das Modell wird dann anhand von F-Score , Precision und Recall bewertet. spaCy hat hierf\u00fcr einen einfachen Terminalbefehl. python -m spacy evaluate de_fnhd_nerdh ./data/datensets/trainData.spacy Das Output sollte dann in etwa so aussehen: \u2139 Using CPU ================================== Results ================================== TOK 100.00 NER P 94.85 NER R 91.06 NER F 92.92 SPEED 2297 =============================== NER (per type) =============================== P R F PERSON 94.81 91.41 93.08 ZEIT 92.64 91.89 92.27 ORT 95.94 94.26 95.09 OBJEKT 94.44 81.79 87.66 ORGANISATION 95.59 82.28 88.44 Mit diesen Werten k\u00f6nnen wir ziemlich zufrieden sein. Sollte das allerdings nicht der Fall sein, dann w\u00fcrden wir einfach unseren Trainingsprozess mit kleinen Ver\u00e4nderungen nochmal erneut starten. Allerdings bedeutet der Wert nur, dass das selbst erstellte Modell de_fnhd_nerdh besonders gut mit Texten von Philipp Hainhofer funktioniert (F-Score 0.92), da es mit diesen trainiert wurden. Nur weil ein Text in fr\u00fchneuhochdeutsch geschrieben wurde, ist dies keine Garantie f\u00fcr ein gutes Ergebnis mit diesem Modell. Der Grund: Historische Texte sind zu spezifisch, als dass sie in einem Modell zusammengefasst werden k\u00f6nnten. Interaktive Notebooks Der Code zu diesem Kapitel befindet sich hier: notebooks/04_trainEvaluateModel_spacy.ipynb . mybinder.org Github Hier geht es zum Jupyter Notebook auf mybinder.org Das Laden des Workspaces wird einen kurzen Moment in Anspruch nehmen. Hier geht es zum Notebook auf Github spaCy. Industrial-strength Natural Language Processing in Python. https://spacy.io/ \u21a9 spaCy. Industrial-strength Natural Language Processing in Python. https://spacy.io/usage \u21a9 spaCy. Industrial-strength Natural Language Processing in Python. https://spacy.io/models/de \u21a9 Schumacher, M. K. (2020). Named Entity Recognition und Reverse Engineering. Lebe lieber literarisch. https://lebelieberliterarisch.de/ named-entity-recognition-und-reverse-engineering/ \u21a9 datasolut GmbH. (2021). Was sind Trainingsdaten im Machine Learning? - datasolut Wiki. https://datasolut.com/wiki/trainingsdaten-und-testdaten-machine-learning/ \u21a9","title":"NER Tutorial mit Spacy"},{"location":"tut/#ner-tutorial-mit-spacy","text":"In dem Tutorial werden wir das Natural Language Processing (NLP) Tool spaCy n\u00e4her kennenlernen. Auch wenn spaCy im NLP Bereich mehr zu bieten hat als nur Named Entity Recogniton (NER), wird darauf der Fokus des Tutorials liegen. Starten werden wir mit einer allgemeinen Einf\u00fchrung in spaCy , in welcher wir die grundlegenden Funktionen f\u00fcr Textanalyseverfahren wie NER kennenlernen werden. Im zweiten Teil des Tutorials werden wir Schritt f\u00fcr Schritt lernen, wie man mit spaCy ein eigenes NER Modell trainiert. Als Trainingstext wird der Reisebericht M\u00fcnchen 1611 aus der digitalen Edition Philipp Hainhofer verwendet. Als Testtext M\u00fcnchen 1603 aus der Edition. Jupyter Notebooks In diesem Tutorial werden lediglich die Code Beispiele dargestellt. F\u00fcr die eigene Benutzung bieten sich folgende drei M\u00f6glichkeiten an: Github Repository Download Jupyter Notebook auf mybinder.org (durch die Verkn\u00fcpfung des Github Repositorys sind die interaktiven Notebooks direkt im Browser zu verwenden.) Kopieren des Codes in ein eigenes Dokument (Kopiersymbol in der rechten oberen Ecke). Github mybinder.org easyh/NerDH git clone https://github.com/easyh/NerDH.git Die Jupyter Notebooks sind im Ordner notebooks hinterlegt. Hier geht es zu allen Jupyter Notebooks auf mybinder.org Das Laden des Workspaces wird einen kurzen Moment in Anspruch nehmen. Viel Spa\u00df!","title":"NER Tutorial mit spaCy"},{"location":"tut/#_1","text":"","title":""},{"location":"tut/#1-einfuhrung-in-spacy","text":"Zun\u00e4chst wird die Bibliothek spaCy von der theoretischen Seite vorgestellt. Anschlie\u00dfend werden wir die Schritte zur Installation von spaCy und zum Herunterladen der vortrainierten Sprachmodelle durchgehen.","title":"1. Einf\u00fchrung in spaCy"},{"location":"tut/#11-was-ist-spacy","text":"spaCy ist ein leistungsstarkes Tool zur Verarbeitung nat\u00fcrlicher Sprache. Die NLP-Bibliothek f\u00fcr maschinelles Lernen wird seit 2016 von Explosion AI stetig weiterentwickelt und befindet sich mittlerweile in der dritten Version ( v.3.4.1 ). Das ist auch die Version, mit der wir hier im Tutorial arbeiten werden. Explosion AI ist ein Berliner Team aus Informatikern und Computerlinguisten. Die Software-Bibiliothek unterst\u00fctzt 70 europ\u00e4ische Sprachen mit statistischen Modellen, die in der Lage sind Texte zu parsen, Wortteile zu identifizieren und Entit\u00e4ten zu extrahieren. Zudem ist spaCy auch in der Lage, benutzerdefinierte Modelle auf dom\u00e4nenspezifsche Texte zu verbessern bzw. von Grund auf zu trainieren. F\u00fcr 24 von 70 unterst\u00fctzten insgesamt bietet spaCy bereits trainierte Pipelines mit unterschiedlichen Package-Gr\u00f6\u00dfen an. Weitere sind in Aussicht. 1 Leistungsumfang von spaCy Programming Language Python Neural network methods Neuronale Netze sind eine Reihe von Algorithmen. Sie interpretieren sensorische Daten durch eine Art maschinelle Wahrnehmung, indem sie den rohen Input kennzeichnen oder in Gruppen zusammenfassen. Die Muster, die sie erkennen, sind numerisch und in Vektoren enthalten. Link Integrated word vectors Die \u00c4hnlichkeit von W\u00f6rtern wird durch den Vergleich von Wortvektoren oder Worteinbettungen, mehrdimensionalen Bedeutungsdarstellungen eines Wortes, ermittelt. Wortvektoren k\u00f6nnen mit einem Algorithmus wie word2vec erzeugt werden Link Multi-language support Unterst\u00fctzt insgesamt 64 Sprachen und hat bereits trainierte Pipelines f\u00fcr 24 Sprachen. Link Tokenization Bei der Tokenisierung wird ein Text in Segemente wie W\u00f6rter oder Satzzeichen, so genannte Token, zerlegt. Die Eingabe f\u00fcr den Tokenizer ist ein Unicode-Text, und die Ausgabe ist ein Doc-Objekt. Link Part-of-Speech-Tagging Darunter versteht man die Zuordnung von W\u00f6rtern und Satzzeichen eines Textes zu Wortarten (engl. part of speech ). Hierzu wird sowohl die Definition des Wortes als auch der Kontext ber\u00fccksichtigt. Link Sentence segmentation Diese Aufgabe beinhaltet die Identifizierung von Satzgrenzen zwischen W\u00f6rtern in verschiedenen S\u00e4tzen. Link Lemmatization Lemmatisierung ist der Prozess der Gruppierung der gebeugten Formen eines Wortes, damit sie als ein einziges Element analysiert werden k\u00f6nnen, das durch das Lemma des Wortes oder die W\u00f6rterbuchform identifiziert wird Link Dependency Parsing Beim Dependency Parsing (DP) werden die Abh\u00e4ngigkeiten zwischen den W\u00f6rtern eines Satzes untersucht, um seine grammatische Struktur zu analysieren. Auf dieser Grundlage wird ein Satz in mehrere Komponenten zerlegt. Der Mechanismus basiert auf dem Konzept, dass es zwischen jeder sprachlichen Einheit eines Satzes eine direkte Verbindung gibt. Diese Verbindungen werden als Abh\u00e4ngigkeiten bezeichnet. Link Named Entity Recognition spaCy kann verschiedene Arten von benannten Entit\u00e4ten in einem Dokument erkennen, indem es das Modell um eine Vorhersage bittet. Da Modelle statistisch sind und stark von den Beispielen abh\u00e4ngen, mit denen sie trainiert wurden, funktioniert dies nicht immer perfekt und muss je nach Anwendungsfall m\u00f6glicherweise sp\u00e4ter angepasst werden. Link Named Entity Linking Um die benannten Entit\u00e4ten in der \"realen Welt\" zu verankern, bietet spaCy Funktionen f\u00fcr das Entity Linking, bei dem eine textuelle Entit\u00e4t in einen eindeutigen Identifikator aus einer Wissensbasis (KB) aufgel\u00f6st wird. Es kann eine eigene KnowledgeBase erstellt und einen neuen EntityLinker mit dieser Wissensbasis trainiert werden. Link Wie wir sehen, stellt Named Entity Recognition nur ein Bruchteil des Leistungsumfangs von spaCy dar. Daher ist ein Blick in die spaCy Dokumentation f\u00fcr weiterf\u00fchrende Informationen sehr empfehlenswert. Ebenfalls zu empfehlen ist das Tutorial von spaCy , welches den vollen Leistumgsumfang ber\u00fccksichtigt.","title":"1.1 Was ist spaCy?"},{"location":"tut/#12-installation-spacy","text":"Um spaCy zu installieren, muss nur Folgendes im Terminal eingeben werden 2 . pip install spacy Wenn spaCy vorher noch nie verwendet wurde, m\u00fcssen die Modelle/Pipelines noch heruntergeladen werden, damit wir mit diesen arbeiten k\u00f6nnen. Da wir NER mit deutschen Texten machen m\u00f6chten, sind f\u00fcr uns erstmal nur die deutschen Sprachmodelle von spaCy interessant. spaCy Deutsche Sprackpakete 3 Name Precision Recall F-Score NE-Typen Word-Vectors Gr\u00f6\u00dfe de_core_news_sm 0.83 0.82 0.82 LOC, MISC, ORG, PER 0 13MB de_core_news_md 0.85 0.84 0.84 LOC, MISC, ORG, PER 20.000 42MB de_core_news_lg 0.85 0.85 0.85 LOC, MISC, ORG, PER 300.000 541MB Es gibt zwar noch das Paket de_core_news_trf , allerdings enth\u00e4lt das Paket keine NER-Pipeline, sodass es f\u00fcr unsere Zwecke nicht relevant ist. Wie wir sehen, unterscheiden sich die Pakete besonders hinsichtlich ihrer Gr\u00f6\u00dfe. Verantwortlich daf\u00fcr ist die Anzahl der Word Vectors/Worteinbettungen . Eine h\u00f6here Anzahl von Word Vectors kann f\u00fcr die Ermittlung der Named Entites von Bedeutung sein. Mehr Infos zu den Sprachpaketen von spaCy gibt es hier . Precision, Recall, F-Score 4 Precision: Berechnet man, indem man die Zahl der richtig gefundenen Vorkommnisse einer Kategorie durch die Gesamtzahl der Markierungen einer Kategorie teilt\u200b. Wurden z.B. 100 Frauenfiguren im Text markiert, davon sind aber nur 97 richtig, so ist P 97:100=0,97 oder 97% . Recall: Berechnet man, indem man die Zahl der richtig gefundenen Vorkommnisse einer Kategorie durch die Gesamtzahl der tats\u00e4chlichen Vorkommnisse einer Kategorie teilt. Wurden z.B. 100 Frauenfiguren im Text richtig markiert, insgesamt gibt es aber 150 Ausdr\u00fccke, die Frauenfiguren bezeichnen, so ist R 100:150=0,66 oder 66% . F-Score: Kombiniert die Werte von Precision und Recall miteiander. Ein Wert nahe 1 bzw. 100% ist sehr gut. Die Sprachpakete k\u00f6nnen mit folgenden Befehlen heruntergeladen werden. python - m spacy download de_core_news_sm python - m spacy download de_core_news_md python - m spacy download de_core_news_lg Mit folgendem Befehl k\u00f6nnen wir uns unsere spaCy -Version sowie die bereits installierten Modelle/Pipelines anzeigen lassen. python -m spacy info","title":"1.2 Installation spaCy"},{"location":"tut/#_2","text":"","title":""},{"location":"tut/#2-erste-schritte-mit-spacy","text":"Bevor wir nun mit der Erkennung von Named Entities und deren Visualisierung beginnen, lernen wir zun\u00e4chts ein paar grundlegende Objekte und Funktionen von spaCy kennen. Bis auf den ersten Codeteil sind die anderen NLP-Funktionen f\u00fcr unsere NER-Aufgabe nicht wichtig, sollen aber dennoch kurz vorgestellt werden, da sie wichtige Grundlagen f\u00fcr Textanalysen sind. Code Output #zuerst importieren wir spaCy import spacy #in der Variable text ist der Text gespeichert, der analysiert werden soll. text = \"Mia M\u00fcller wohnt in Trier und studiert an der Universit\u00e4t Trier. Aufgewachsen ist sie in M\u00fcnchen mit ihrem Bruder Tom.\" #Als n\u00e4chstes m\u00fcssen wir ein Modellobjekt laden. #Hierf\u00fcr verwenden wir die Funktion spacy.load(). #Diese nimmt ein Argument entgegen, n\u00e4mlich das Modell, das wir laden m\u00f6chten. #Wir werden das kleine deutsche Modell verwenden. nlp = spacy . load ( \"de_core_news_sm\" ) #Nachdem wir das nlp-Objekt erstellt haben, k\u00f6nnen wir es verwenden, um einen Text zu analysieren. #Zu diesem Zweck erstellen wir ein doc-Objekt. #Dieses Objekt wird eine Menge Daten \u00fcber den Text enthalten. doc = nlp ( text ) #Wir testen, ob das doc-Objekt unseren Text \u00fcbernommen hat. print ( doc ) Mia M\u00fcller wohnt in Trier und studiert an der Universit\u00e4t Trier. Aufgewachsen ist sie in M\u00fcnchen mit ihrem Bruder Tom. Sentence Tokenizer Code Output for sent in doc . sents : print ( sent ) Mia M\u00fcller wohnt in Trier und studiert an der Universit\u00e4t Trier. Aufgewachsen ist sie in M\u00fcnchen mit ihrem Bruder Tom. Part-of-Speech Tagging Code Output for token in doc : print ( token . text , token . pos_ ) Mia PROPN M\u00fcller PROPN wohnt VERB in ADP Trier PROPN und CCONJ studiert VERB an ADP der DET Universit\u00e4t NOUN Trier PROPN . PUNCT Aufgewachsen VERB ist AUX sie PRON in ADP M\u00fcnchen PROPN mit ADP ihrem DET Bruder NOUN Tom PROPN . PUNCT Erl\u00e4uterung der POS-Tags POS-Tag Erl\u00e4uterung PROPN Substantiv (Name einer Person) NOUN Substantiv VERB Verben ADJ Adjektiv ADV Adverb ADP Pr\u00e4-/Adpositionen DET Begleiter AUX Hilfsverb PUNCT Interpunktion CCONJ Konjunktion Substantive und Substantiv-Bausteine extrahieren Code Output for chunk in doc . noun_chunks : print ( chunk . text ) Mia Trier der Universit\u00e4t Trier sie M\u00fcnchen ihrem Bruder Tom Verben extrahieren Code Output #Verben sind im POS-TAg als \"VERB\" oder \"AUX\" definiert, daher iterieren wir f\u00fcr \u00fcber alle POS-TAGS, die \u00fcbereinstimmen. verbs = [ \"VERB\" , \"AUX\" ] for token in doc : if token . pos_ in verbs : print ( token . text , token . pos_ ) wohnt VERB studiert VERB Aufgewachsen VERB ist AUX Lemmatisierung Code Output for token in doc : print ( token . text , token . lemma_ ) Mia Mia M\u00fcller M\u00fcller wohnt wohnen in in Trier Trier und und studiert studieren an an der der Universit\u00e4t Universit\u00e4t Trier Trier . -- Aufgewachsen aufgewachsen ist sein sie sie in in M\u00fcnchen M\u00fcnchen mit mit ihrem ihr Bruder Bruder Tom Tom . --","title":"2. Erste Schritte mit spaCy"},{"location":"tut/#21-entitaten-erkennen","text":"Der Code um Named Entities in einem Dokument zu erkennen ist \u00e4hnlich simpel wie der Code der anderen Funktionen. Wir iterieren erneut \u00fcber unser doc-Objekt mit der Funktion .ents . Code Output for ent in doc . ents : print ( ent . text , ent . label_ ) Mia M\u00fcller PER Trier LOC Universit\u00e4t Trier. ORG M\u00fcnchen LOC Tom. PER Wie wir sehen, hat das kleine Sprachmodell hier sehr gute Arbeit geleistet. Alle vorkommenden Named Entities wurden richtig erkannt. Sogar die zwei W\u00f6rter Universit\u00e4t und Trier wurden als ORGANISATION verstanden und nicht nur als ORT . Dieses Ph\u00e4nomen wird auch als Nested Entities bezeichnet, weil in einer Entit\u00e4t gleich mehrere stecken k\u00f6nnen. Um beispielsweise nur die benannten Entit\u00e4ten zu extrahieren, die beispielsweise als PERSON identifiziert wurden, k\u00f6nnen wir eine einfache if-Anweisung in den Mix einf\u00fcgen. Code Output for ent in doc . ents : if ent . label_ == \"PER\" : print ( ent ) Mia M\u00fcller Tom. Wir k\u00f6nnen uns zus\u00e4tzlich noch ausgeben lassen, an welcher Stelle im Text die Named Entities zu finden sind. Code Output for ent in doc . ents : print ( ent . text , ent , start_char , ent . end_char , ent . label_ ) Mia M\u00fcller 0 10 PER Trier 20 25 LOC Universit\u00e4t Trier. 46 64 ORG M\u00fcnchen 89 96 LOC Tom. 114 118 PER","title":"2.1 Entit\u00e4ten erkennen"},{"location":"tut/#22-ner-visualisieren","text":"spaCy hat eine eingebaute Funktion zur Visualisierung der Entit\u00e4ten namens displacy . Der schnellste Weg, ein doc-Objekt zu visualisieren ist displacy.serve . Dadurch wird ein einfacher Webserver gestartet und das Ergebnis kann im Browser betrachtet werden. Da wir innerhalb eines Jupyter Notebooks arbeiten, verwenden wir die Funktion displacy.render . Zun\u00e4chst m\u00fcssen wir dazu noch displacy importieren. Code Output from spacy import displacy displacy . render ( doc , style = \"ent\" ) Mia M\u00fcller PER wohnt in Trier LOC und studiert an der Universit\u00e4t Trier. ORG Aufgewachsen ist sie in M\u00fcnchen LOC mit ihrem Bruder Tom. PER Hier k\u00f6nnen wir jetzt noch eigene Anpassungen wie die Auswahl der Entit\u00e4ten, als auch die Farbe ausf\u00fchren. Die individuellen Farben geben wir f\u00fcr alle vier Entit\u00e4tstypen an, allerdings wollen wir uns hier nur die Personen ( PER ) und Orte ( LOC ) ausgeben lassen. Code Output colors = { \"PER\" : \"#fdec3e\" , \"LOC\" : \"#7e56c2\" , \"ORG\" : \"#209485\" , \"MISC\" : \"#eb4034\" } options = { \"ents\" : [ \"PER\" , \"LOC\" ], \"colors\" : colors } displacy . render ( doc , style = \"ent\" , options = options ) Mia M\u00fcller PER wohnt in Trier LOC und studiert an der Universit\u00e4t Trier. Aufgewachsen ist sie in M\u00fcnchen LOC mit ihrem Bruder Tom. PER Jupyter Notebooks Der Code zu diesem Kapitel befindet sich hier: notebooks/01_firstSteps_spacy.ipynb . Github mybinder.org Hier geht es zum Notebook auf Github Hier geht es zum Jupyter Notebook auf mybinder.org Das Laden des Workspaces wird einen kurzen Moment in Anspruch nehmen.","title":"2.2 NER visualisieren"},{"location":"tut/#_3","text":"","title":""},{"location":"tut/#3-eigenes-modell-trainieren-mit-spacy","text":"Je nach Anwendungsfall macht es wenig Sinn nur mit dem Standardmodell zu arbeiten. Weshalb es besser ist, ein neues Modell zu trainieren bzw. auf ein bestehendes aufzubauen. Besonders bei historischen Texten entstehen Probleme und Schwierigkeiten aufgrund ihrer Heterogenit\u00e4t. NER mit fnhd. Text Folgendes Beispiel zeigt, wie das kleine spaCy Sprachmodell mit einem Satz aus dem fr\u00fchneuhochdeutschen abschneidet. Der Satz ist aus unserem Traningstext M\u00fcnchen 1611 von Philipp Hainhofer. Code Output text_fnhd = \"Aines m\u00f6rders Conterfett, genant Christoff Froschhammer von Vlingingen, der Hat 345 m\u00f6rd, mit seiner aignen hand, vnd 400 mord in gesellschafft anderer, gethan, ist Anno 1578 zu Wel\u00df in Ste\u00ffrmarck gerichtet worden, vnd au\u00df dem stifft Saltzburg geb\u00fcrtig gewesen.\" nlp = spacy . load ( \"de_core_news_sm\" ) doc_fnhd = nlp ( text_fnhd ) for ent in doc_fnhd . ents : print ( ent . text , ent . label_ ) Aines m\u00f6rders MISC Christoff Froschhammer PER Anno LOC Wel\u00df PER Ste\u00ffrmarck MISC Saltzburg LOC Wie wir sehen wurden nur zwei Entit\u00e4ten richtig erkannt: Christoff Froschhammer als PERSON und Saltzburg als ORT . Vlingingen , sowie Wel\u00df und Ste\u00ffrmarck wurden nicht richtig oder garnicht als ORT erkannt. Zudem hat das Modell Entit\u00e4ten erkannt, die eigentlich keine Entit\u00e4ten sind: Anno und Aines m\u00f6rder . Vor dem Training eines eigenen NER-Modells ist es wichtig, folgende drei Fragen zu kl\u00e4ren: Was sind die Daten? Unsere Daten entstammen der digitalen Edition Philipp Hainhofer . Hier haben wir uns f\u00fcr den Reisebericht M\u00fcnchen 1611 als Trainingstext und M\u00fcnchen 1603 als Testtext entschieden. Die Texte der Edition stehen in TEI-XML , PDF sowie TXT zum Download verf\u00fcgbar. Wir verwenden die Daten im TXT -Format, denn einige Studien haben gezeigt, dass eine umfangreiche XML-Annotation, die dem NER-Prozess vorausgeht, die Leistung beeintr\u00e4chtigen kann. NER-Systeme sollten daher idealerweise angewendet werden, bevor ein Korpus mit Standards wie TEI annotiert wird. In dieser Reihenfolge k\u00f6nnen die NER-Ergebnisse dann auch bei der TEI-Codierung sehr hilfreich sein. Welche Entit\u00e4ten m\u00f6chte ich ausw\u00e4hlen? Hier geht es darum, die relevanten Kategorien und Entit\u00e4ten auszuw\u00e4hlen. Daf\u00fcr ist es wichtig zu wissen, welche und wie viele NE-Katogorien man f\u00fcr die jeweiligen Texte verwenden will. In unserem Modell werden wir die folgenden Entit\u00e4ten trainieren: Named Entities Beschreibung PERSON Einzelperson oder Familie ORT Geographische Einheit, d. h. L\u00e4nder, St\u00e4dte, Staaten, Fl\u00fcsse ORGANISATION Institutionen,(Ordens-)Gemeinschaften, Verbindungen, etc. OBJEKT Architektur, Geb\u00e4ude, Kunst, Werke etc. ZEIT Datum, Monat, Jahr, Uhrzeit etc. Wie m\u00f6chte ich diese Entit\u00e4ten kennzeichen? Hier geht es darum, wie die Entit\u00e4ten annotiert werden. Dabei sollte sich auf eine einheitliche Annotationskonvention beschr\u00e4nkt werden. Das Ergebnis sollte am ein Ende ein Goldstandard sein, anhand dessen sp\u00e4ter das NER-Modell bewertet wird, indem die per Hand angefertigen Annotationen mit der Ausgabe des NER-Systems verglichen werden. Im Laufe dieses Kapitels werden wir lernen, wie das Training eines eigenen Modells mit spaCy umgesetzt wird. Unser Workflow f\u00fcr das Training eines eigenen NER-Modells sieht wie folgt aus: Workflow: Training eines eigenen NER Modells","title":"3. Eigenes Modell trainieren mit spaCy"},{"location":"tut/#31-preprocessing","text":"Bevor wir mit dem Trainings- und dem anschlie\u00dfenden Evaluierungsprozess starten, m\u00fcssen wir zun\u00e4chst einen Goldstandard erstellen und diesen dann in Trainings-, Validierungs- & Testdaten aufteilen. Dieser Schritt geh\u00f6rt zum sogennanten Preprocessing des maschinellen Lernens. Vor der Annotation des Goldstandards, sollten wir unsere beiden Texte allerdings noch etwas kennenlernen und vorbereiten. Auf die n\u00e4here Ausf\u00fchrung soll an dieser Stelle verzichtet werden, allerdings ist alles wichtige zu diesem Schritt im Notebook 02_preprocessingText.ipynb festgehalten. Jupyter Notebooks Der Code zu diesem Kapitel befindet sich hier: notebooks/02_preprocessingText.ipynb . Github mybinder.org Hier geht es zum Notebook auf Github Hier geht es zum Jupyter Notebook auf mybinder.org Das Laden des Workspaces wird einen kurzen Moment in Anspruch nehmen.","title":"3.1 Preprocessing"},{"location":"tut/#311-annotation-eines-goldstandards","text":"Die Annotation des Goldstandrds ist der erste wichtige Schritt, um ein Trainingskorpus zu erstellen. Goldstandard Ein Goldstandard ist eine manuelle Referenz-Annotation, bei der die relevanten Named Entities annotiert werden. Es ist die finale Version der annotierten Daten, die f\u00fcr den Trainingsprozess verwendet werden. Je besser und genauer die Auszeichnungen f\u00fcr den Goldstandard gemacht werden, desto besser ist das Trainingsergebnis. Anhand des Goldstandards, kann sp\u00e4ter die Qualit\u00e4t eines NER-Modell bewertet werden, quantifziert als Recall, Precision und F-Score. Es gibt mehrere M\u00f6glichkeiten Texte so zu annotieren, dass sie maschinenlesbar sind. Hier muss je nach Anwendungsbereich entschieden werden, welcher Annotationsstandard der passendste ist. In den Digital Humanities werden die meisten Texte mithilfe der auf XML basierenden Anwendung der Text Encoding Initiative (TEI) annotiert. Ein anderer bekannter Standard zum Annotieren von Named Entities ist das IOB-Schema (bzw. BIO-Schema). Da wir allerdings ein NER-Modell mit spaCy trainieren wollen, m\u00fcssen wir unseren Goldstandard entsprechend f\u00fcr die Software anpassen. spaCy verlangt ein spezielles Traningsformat, in welchem die Daten vorliegen m\u00fcssen. Das Beispiel zeigt das klassische Format: TRAIN_DATA = [\"TEXT AS A STRING\",{\"entities:\"[(START,END,LABEL)]}] Es gibt zahlreiche Auszeichnungstools, die f\u00fcr Anwendungen des maschinellen Lernens entwickelt wurden und bei der Annotation von Texten helfen. Darunter auch einige, welche die Daten direkt in das entsprechende Trainingsformat f\u00fcr spaCy bringen. Daf\u00fcr wurde speziell prodigy entwickelt, was allerdings kostenpflichtig ist. Aber es gibt auch einige Open-Source-Programme, die eine gute Alternative darstellen. Wir haben unseren Goldstandard mit dem NER-Annotator erstellt. Hier kann ein Text im TXT -Format importiert, annotiert und dann anschlie\u00dfend im JSON -Format exportiert werden. Die JSON -Datei enth\u00e4lt dann die annotierten Daten, die in dem f\u00fcr spaCy geeigneten Format vorliegen. Allerdings m\u00fcssen die JSON -Dateien f\u00fcr den Trainingsprozess nochmal in .spacy -Dateien umgewandelt werden. Der NER-Annotator stellt hier Code zur Verf\u00fcgung (n\u00e4heres dazu im n\u00e4chsten Kapitel zur Erstellung der Datensets). Das folgende Bild zeigt, wie die Annotation erfolgt. In der oberen Zeile k\u00f6nnen die Entit\u00e4ten Kategorien festgelegt werden. Ist eine Kategorie mit einem Haken markiert (hier ORT ) kann im Text damit die entsprechende Entit\u00e4t markiert werden. So arbeiten wir uns St\u00fcck f\u00fcr St\u00fcck durch unseren Text, bis wir fertig sind. Enth\u00e4lt ein Satz keine Entit\u00e4ten, dann \u00fcberspringen ( skip ) wir diesen. In unserer Datei sind sp\u00e4ter nur S\u00e4tze enthalten, die Entit\u00e4ten enthalten. Erstellung des Goldstandards f\u00fcr das Training mit dem NER-Annotator-for-spaCy. In der JSON -Datei ist dieser Satz dann im folgenden Format wieder zu finden: { \"classes\" : [ \"PERSON\" , \"ORT\" , \"ORGANISATION\" , \"OBJEKT\" , \"ZEIT\" ], \"annotations\" : [[ \"Aines m\u00f6rders Conterfett, genant Christoff Froschhammer von Vlingingen, der Hat 345 m\u00f6rd, mit seiner aignen hand, vnd 400 mord in gesellschafft anderer, gethan, ist Anno 1578 zu Wel\u00df in Ste\u00ffrmarck gerichtet worden, vnd au\u00df dem stifft Saltzburg geb\u00fcrtig gewesen.\" , { \"entities\" : [[ 33 , 55 , \"PERSON\" ],[ 60 , 70 , \"ORT\" ],[ 165 , 174 , \"ZEIT\" ],[ 178 , 182 , \"ORT\" ],[ 186 , 196 , \"ORT\" ],[ 234 , 243 , \"ORT\" ]]}]]} Der Prozess des Annotieren kann je nach L\u00e4nge des Textes sehr aufw\u00e4ndig und anstrengend sein. Bei sehr langen Texten bietet es sich an, den Text in einzelene Dateien zu unterteilen, um dann in Etappen die Annotation durchzuf\u00fchren. Am Ende k\u00f6nnen die einzelnen JSON -Dateien, dann wieder zu einer Datei zusammengef\u00fcgt werden, die dann den finalen Goldstandard darstellt. Die folgende Tabelle soll einen kurzen \u00dcberblick \u00fcber den Trainingstext M\u00fcnchen 1611 und den Testtext M\u00fcnchen 1603 und dessen annotierten Enitit\u00e4ten geben. Text S\u00e4tze Tokens/W\u00f6rter Zeichen PERSON ORT ORG OBJEKT ZEIT Gesamt Entit\u00e4ten M\u00fcnchen 1611 1 595 41 087 225 952 1019 840 63 238 451 2611 M\u00fcnchen 1603 147 5 928 31 747 54 55 16 53 22 200 GESAMT 1 742 47 015 257 699 1073 895 79 291 473 2811 Der Goldstandard f\u00fcr den Traningstext befindet sich hier ( data/datensets/taggedData.json ).","title":"3.1.1 Annotation eines Goldstandards"},{"location":"tut/#312-training-validierung-und-testdaten","text":"Beim maschinellen Lernen ben\u00f6tigen wir einen Trainingsdatensatz, um ein Modell richtig zu trainieren und einen Testdatensatz, um das Modell zu bewerten. Der Datensatz taggedData.json umfasst den komplett annotierten Text M\u00fcnchen 1611 . Bei \u00fcberwachten Lernmethoden wird dieser Datensatz in der Regel in mindestens drei verschiedene Datens\u00e4tze unterteilt: Training-, Validierung- und Testdaten . In unserem Fall \u00fcbernehmen die Trainingsdaten ( testData.json ) bei uns die annotierten Daten aus dem Text M\u00fcnchen 1603 . \u00dcberwachtes Lernen In unserem Fall arbeiten wir mit der \u00fcberwachten Lernmethode , bei der Beispieldaten in Form eines annotierten Goldtstandards notwendig sind, damit der Algoritmus lernen kann. Bei un\u00fcberwachten Lernmethode hingegen br\u00e4uchten wir keine Beispiele, da hier direkt mit den Eingabedaten trainiert wird und der Algorithmus hier von selbst Muster und Zusammenh\u00e4nge lernen w\u00fcrde. Die Aufteilung unsrer Daten sieht wie folgt aus. Den Datensatz taggedData.json werden wir noch in Trainingsdaten und Validierungsdaten einteilen m\u00fcssen. Aufteilung in Training-, Validierung- und Testdaten. Training-, Validierung- und Testdaten 5 Datensatz Anteil Erkl\u00e4rung Traningsdaten 70% Ein Trainingsdatensatz ist eine Sammlung von Beispielen, die verwendet werden, um einem Algorithmus beizubringen, Muster und Zusammenh\u00e4nge in den Daten zu erkennen. Der Algorithmus passt seine Gewichte anhand der Trainingsdaten an, indem er aus ihnen lernt. Trainingsdaten werden f\u00fcr Klassifikations- und Regressionsprobleme ben\u00f6tigt, bei denen es darum geht, Vorhersagen f\u00fcr bestimmte Zielvariablen zu treffen. Es kann vorkommen, dass Algorithmen, die auf Trainingsdaten lernen, zu sehr auf die Muster in diesen Daten angepasst werden und somit nicht gut auf neue, noch nicht gesehene Daten anwendbar sind. Dies wird als \"\u00dcberanpassung\" oder \"Overfitting\" bezeichnet. Das bedeutet, dass der Algorithmus zu starke Regeln aus den Trainingsdaten lernt, die auf die Gesamtheit der Daten nicht gut anwendbar sind. Validierungsdaten 20% Der Validierungsdatensatz ist eine Sammlung von Beispieldaten, die verwendet werden, um die Hyperparameter eines Modells anzupassen. Hyperparameter sind Einstellungen, die vor dem Training festgelegt werden und Einfluss auf das Lernverhalten des Modells haben. Beispiele f\u00fcr Hyperparameter bei k\u00fcnstlichen neuronalen Netzen sind die Anzahl der Neuronen in jeder Schicht oder die Lernrate. Durch die Verwendung von Validierungsdaten beim Training kann verhindert werden, dass das Modell zu sehr auf die Trainingsdaten angepasst wird und somit auf neue, noch nicht gesehene Daten nicht gut anwendbar ist. Testdaten 10% Die Testdaten sind von den Trainingsdaten unabh\u00e4ngig und werden w\u00e4hrend des Trainingsprozesses nicht verwendet. Sie dienen dazu, das trainierte Modell zu bewerten und zu \u00fcberpr\u00fcfen, wie gut es auf neue, noch nicht gesehene Daten anwendbar ist. Die Testdaten sollten dieselbe Wahrscheinlichkeitsverteilung wie der Trainingsdatensatz aufweisen. Wenn das Modell gut auf die Testdaten anwendbar ist, kann es vermutlich auch auf andere, bisher ungesehene Daten angewendet werden. Um jetzt unseren gro\u00dfen Datensatz taggedData.json in zwei Datensets aufzuteilen, lesen wir diesen zun\u00e4chts ein und speichern nur die Eintr\u00e4ge von annotations in der Variablen TAGGED_DATA , damit wir die Eintr\u00e4ge z\u00e4hlen k\u00f6nnen. Danach ermitteln wir die Grenze (80:20), damit wir den ursp\u00fcnglichen Datensatz in kleinere Datens\u00e4tze zu je 80% und 20%. Code Output import json f = open ( '../data/datensets/taggedData.json' ) data = json . load ( f ) TAGGED_DATA = data [ 'annotations' ] print ( len ( TAGGED_DATA ) * 0.8 ) 696.8000000000001 Bevor wir den Datensatz an der ermittelten Grenzen in die zwei Datensets aufteilen, mischen wir die Eintr\u00e4ge noch einmal durch, damit die Verteilung zuf\u00e4llig ist. Hier lassen wir uns dann jeweils die L\u00e4nge ausgeben, um das Ergebnis zu \u00fcberpr\u00fcfen. Zus\u00e4tzlich lassen wir uns auch noch die Gr\u00f6\u00dfe des Testdatensatz ausgeben, um zu \u00fcberpr\u00fcfen, ob die 70:20:10 Verteilung ungef\u00e4hr hinhaut. Code Output import random random . shuffle ( TAGGED_DATA ) train_data = TAGGED_DATA [: 697 ] val_data = TAGGED_DATA [ 697 :] print ( \"Traningsdaten: \" + str ( len ( train_data ))) print ( \"Validierungsdaten: \" + str ( len ( val_data ))) #Zum vergleich, lassen wir uns auch die G\u00f6\u00dfe von unseren Testdaten ausgeben f = open ( '../data/datensets/testData.json' ) data = json . load ( f ) test_data = data [ 'annotations' ] print ( \"Testdaten: \" + str ( len ( test_data ))) Traningsdaten: 697 Validierungsdaten: 174 Testdaten: 87 Anschlie\u00dfend speichern wir die Datensets im JSON -Format ab. Code with open ( '../data/datensets/trainData.json' , 'w' , encoding = 'utf-8' ) as train : json . dump ( train_data , train , ensure_ascii = False , indent = 4 ) with open ( '../data/datensets/valuationData.json' , 'w' , encoding = 'utf-8' ) as val : json . dump ( val_data , val , ensure_ascii = False , indent = 4 ) Da wir weiter oben nur die Eintr\u00e4ge aus annotations der JSON-Datei \u00fcbernommen haben, m\u00fcssen wir jetzt noch einmal manuell bei trainData.json sowie validationData.json die classes hinzuf\u00fcgen, damit unsere Kategorien f\u00fcr die Entit\u00e4ten nicht verloren gehen. Dazu setzen wir an den Anfang des Dokuments folgendes und ans Ende eine } um das Dokument zu schlie\u00dfen. { \"classes\" : [ \"PERSON\" , \"ORT\" , \"ORGANISATION\" , \"OBJEKT\" , \"ZEIT\" ], \"annotations\" : Jetzt m\u00fcssen die Datensets im JSON -Format nurnoch ins spaCy -Format konvertiert werden. Daf\u00fcr importieren wir zun\u00e4chst die ensprechenden Bibliotheken und das mittlere Sprachmodell von spaCy . Code import spacy from spacy.tokens import DocBin from tqdm import tqdm #neues spacy Model laden nlp = spacy . load ( \"de_core_news_md\" ) #DocBin Objekt erstellen db = DocBin () Jetzt m\u00fcssen wir f\u00fcr jedes Datenset nur noch folgenden Code ausf\u00fchren, welcher uns vom NER-Annotator vorgegeben wird, damit die Datensets im spaCy -Datenformat sind. Traningsdaten Validierungsdaten Testdaten f = open ( '../data/datensets/trainData.json' ) TRAIN_DATA = json . load ( f ) for text , annot in tqdm ( TRAIN_DATA [ 'annotations' ]): doc = nlp . make_doc ( text ) ents = [] for start , end , label in annot [ \"entities\" ]: span = doc . char_span ( start , end , label = label , alignment_mode = \"contract\" ) if span is None : print ( \"Skipping entity\" ) else : ents . append ( span ) doc . ents = ents db . add ( doc ) #Docbin Objekt speichern db . to_disk ( \"../data/datasets/trainData.spacy\" ) f = open ( '../data/datensets/valuationData.json' ) VAL_DATA = json . load ( f ) for text , annot in tqdm ( VAL_DATA [ 'annotations' ]): doc = nlp . make_doc ( text ) ents = [] for start , end , label in annot [ \"entities\" ]: span = doc . char_span ( start , end , label = label , alignment_mode = \"contract\" ) if span is None : print ( \"Skipping entity\" ) else : ents . append ( span ) doc . ents = ents db . add ( doc ) #Docbin Objekt speichern db . to_disk ( \"../data/datasets/valuationData.spacy\" ) f = open ( '../data/datensets/testData.json' ) TEST_DATA = json . load ( f ) for text , annot in tqdm ( TEST_DATA [ 'annotations' ]): doc = nlp . make_doc ( text ) ents = [] for start , end , label in annot [ \"entities\" ]: span = doc . char_span ( start , end , label = label , alignment_mode = \"contract\" ) if span is None : print ( \"Skipping entity\" ) else : ents . append ( span ) doc . ents = ents db . add ( doc ) #Docbin Objekt speichern db . to_disk ( \"../data/datasets/testData.spacy\" ) Damit ist das Preprocessing abgeschlossen und wir k\u00f6nnen mit dem Training des Modells beginnen. Jupyter Notebooks Der Code zu diesem Kapitel befindet sich hier: notebooks/03_createDatasets_spacy.ipynb . Github mybinder.org Hier geht es zum Notebook auf Github Hier geht es zum Jupyter Notebook auf mybinder.org Das Laden des Workspaces wird einen kurzen Moment in Anspruch nehmen.","title":"3.1.2 Training-, Validierung- und Testdaten"},{"location":"tut/#33-training","text":"Da wir jetzt alle unsere Daten haben, ist es an der Zeit unser Modell zu trainieren. In spaCy k\u00f6nnen wir die Architektur unserer Netzes sowie die Hyperparamter f\u00fcr unser Modell weitgehend steuern. Dies geschieht in der config.cfg Datei. Diese Konfigurationsdatei wird spaCy w\u00e4hrend dem Trainingsprozess \u00fcbergeben, damit das System wei\u00df, was und wie es trainieren soll. Um die config.cfg Datei zu erstellen, k\u00f6nnen wir die praktische GUI von spaCy selbst benutzen. F\u00fcr unsere Zwecke w\u00e4hlen wir German , ner und CPU (GPU ist etwas komplexer). Jenachdem ob wir ohne Wortvektoren oder mit ihnen trainieren wollen, w\u00e4hlen wir efficiency oder accuracy . In unserem Beispiel haben wir mit accuracy , also mit Wortvektoren trainiert. Hier werden dann die Vektoren des gro\u00dfen deutschen Modell de_core_news_lg \u00fcbernommen (das k\u00f6nnen wir nat\u00fcrlich auch mit dem kleinen bzw. mittleren Modell machen). Diese Datei speichern wir zun\u00e4chst als base_config.cfg ab. Die base_config.cfg -Datei befindet sich ebenfalls auf Github im Ordner notebooks oder kann hier einfach kopiert werden. base_config.cfg [paths] train = null dev = null vectors = \"de_core_news_lg\" [system] gpu_allocator = null [nlp] lang = \"de\" pipeline = [\"tok2vec\",\"ner\"] batch_size = 1000 [components] [components.tok2vec] factory = \"tok2vec\" [components.tok2vec.model] @architectures = \"spacy.Tok2Vec.v2\" [components.tok2vec.model.embed] @architectures = \"spacy.MultiHashEmbed.v2\" width = ${components.tok2vec.model.encode.width} attrs = [\"NORM\", \"PREFIX\", \"SUFFIX\", \"SHAPE\"] rows = [5000, 1000, 2500, 2500] include_static_vectors = true [components.tok2vec.model.encode] @architectures = \"spacy.MaxoutWindowEncoder.v2\" width = 256 depth = 8 window_size = 1 maxout_pieces = 3 [components.ner] factory = \"ner\" [components.ner.model] @architectures = \"spacy.TransitionBasedParser.v2\" state_type = \"ner\" extra_state_tokens = false hidden_width = 64 maxout_pieces = 2 use_upper = true nO = null [components.ner.model.tok2vec] @architectures = \"spacy.Tok2VecListener.v1\" width = ${components.tok2vec.model.encode.width} [corpora] [corpora.train] @readers = \"spacy.Corpus.v1\" path = ${paths.train} max_length = 0 [corpora.dev] @readers = \"spacy.Corpus.v1\" path = ${paths.dev} max_length = 0 [training] dev_corpus = \"corpora.dev\" train_corpus = \"corpora.train\" [training.optimizer] @optimizers = \"Adam.v1\" [training.batcher] @batchers = \"spacy.batch_by_words.v1\" discard_oversize = false tolerance = 0.2 [training.batcher.size] @schedules = \"compounding.v1\" start = 100 stop = 1000 compound = 1.001 [initialize] vectors = ${paths.vectors} Da die base_config.cfg -Datei nun korrekt eingerichtet ist, m\u00fcssen wir sie in eine config.cfg -Datei umwandeln. Dazu m\u00fcssen wir einen Terminalbefehl ausf\u00fchren. Durch Ausf\u00fchren des folgenden Befehls erhalten wir die korrekt formatierte config.cfg -Datei. python -m spacy init fill-config ./base_config.cfg ./config.cfg Jetzt haben wir alles, um unser erstes Modell zu trainieren. Wir erstellen einen Ordner namens output , hier wird unser fertiges Modell dann abgelegt. Wir m\u00fcssen nur den folgenden Befehl ausf\u00fchren, etwas warten und schon haben wir ein trainiertes Modell. Hinter paths.train setzen wir den Pfad zu unseren Trainingsdaten und hinter paths.dev unsere Valuierungsdaten python -m spacy train config.cfg --output ./output --paths.train ./datensets/trainData.spacy --paths.dev ./datensets/valuationData.spacy Trainingsausgabe Die Ausgabe zeigt uns die Epochen, die Anzahl der Stichproben sowie einige Metriken f\u00fcr unser Modell. \u2139 Saving to output directory: output \u2139 Using CPU =========================== Initializing pipeline =========================== [2022-11-19 13:23:54,923] [INFO] Set up nlp object from config [2022-11-19 13:23:54,941] [INFO] Pipeline: ['tok2vec', 'ner'] [2022-11-19 13:23:54,949] [INFO] Created vocabulary [2022-11-19 13:24:00,463] [INFO] Added vectors: de_core_news_lg [2022-11-19 13:24:06,491] [INFO] Finished initializing nlp object [2022-11-19 13:24:09,274] [INFO] Initialized pipeline components: ['tok2vec', 'ner'] \u2714 Initialized pipeline ============================= Training pipeline ============================= \u2139 Pipeline: ['tok2vec', 'ner'] \u2139 Initial learn rate: 0.001 E # LOSS TOK2VEC LOSS NER ENTS_F ENTS_P ENTS_R SCORE --- ------ ------------ -------- ------ ------ ------ ------ 0 0 0.00 85.09 0.00 0.00 0.00 0.00 0 200 880.61 2879.21 55.96 75.37 44.50 0.56 1 400 65.55 1510.84 71.81 67.93 76.15 0.72 2 600 109.01 1268.59 82.27 81.65 82.89 0.82 4 800 78.71 901.58 86.86 87.08 86.64 0.87 5 1000 74.96 737.24 88.99 91.39 86.73 0.89 7 1200 80.31 559.43 90.62 91.06 90.18 0.91 show more (open the raw output data in a text editor) ... 143 5200 180.50 58.97 93.98 93.86 94.10 0.94 151 5400 211.91 75.53 93.96 93.79 94.14 0.94 159 5600 376.93 128.75 94.00 93.98 94.02 0.94 \u2714 Saved pipeline to output directory output/model-last In unserem output -Ordner befinden sich nun zwei Unterordner: model-best und model-last . Beide dieser Modelle k\u00f6nnen jetzt in der spacy.load() Funktion eingelesen und ausprobiert werden. Hier wird dann einfach der Pfad angegeben, wo das Modell liegt. import spacy nlp = spacy . load ( output / model - best ) Im Github Repositry gibt es keinen output -Ordner mit einem Modell, da das trainierte Modell zu gro\u00df ist. Allerdings gibt es von spaCy die M\u00f6glichkeit ein Modell in ein Python Package zu packen, dass dann wie jedes andere Package mit pip install installiert werden kann. Modell als Python Package verpacken Daf\u00fcr m\u00fcssen wir uns einmal in das innere unseres Modells klicken und in der meta.json -Datei noch kleine \u00c4nderungen machen. Bei name vergeben wir dem Modell einen Namen, mit dem wir es laden m\u00f6chten. Zus\u00e4tzlich geben wir noch eine version an: Da es unser erstes Modell ist setzen wir die Version auf 0.0.1 . Nat\u00fcrlich k\u00f6nnen wir hier auch noch mehr Informationen wie z.B. description , author oder email angeben. { \"lang\" : \"de\" , \"name\" : \"de_fnhd_nerdh\" , \"version\" : \"0.0.1\" , \"spacy_version\" : \">=3.4.1,<3.5.0\" , \"description\" : \"\" , \"author\" : \"\" , \"email\" : \"\" , ... } Dann erstellen wir einen Ordner package , hier wird unser verpacktes Modell gespeichert, und geben folgenden Terminalbefehl ein: python -m spacy package ./output/model-best ./package --build wheel Lokal k\u00f6nnen wir unser Modell jetzt installieren einfach wie folgt installieren. Wir m\u00fcssen uns hierf\u00fcr allerdings im Verzeichnis dist befinden oder dorthin navigieren: pip install package/de_fnhd_nerdh-0.0.1/dist/de_fnhd_nerdh-0.0.1-py3-none-any.whl Jetzt k\u00f6nnen wir unser selbst erstelltes Modell wie die spaCy Modelle benutzen. import spacy nlp = spacy . load ( de_fnhd_nerdh ) Modellpackage ver\u00f6ffentlichen Mithilfe von spacy-huggingface-hub k\u00f6nnen wir unser verpacktes Modell ver\u00f6ffentlichen und anderen Usern anbieten. Dazu m\u00fcssen wir uns vorher einen Account auf huggingface.co erstellen und das Package installieren. pip install spacy-huggingface-hub Jetzt k\u00f6nnen wir uns \u00fcber den Terminal in huggingface.co einloggen, damit unser Package unserem Profil zugeordnet wird. Hier werden wir nach einem Token gefragt, den wir hier abrufen k\u00f6nnen. huggingface-cli login Mit folgendem Befehl pushen wir unser Projekt auf huggingface.co . python -m spacy huggingface-hub push package/de_fnhd_nerdh-0.0.1/dist/de_fnhd_nerdh-0.0.1-py3-none-any.whl Der Befehl wird dann zwei Dinge ausgeben: wo das Repository auf huggingface.co gefunden wird Link, mit welchem das Modell installiert werden kann Das Modell, welches hier im Tutorial erstellt wurde kann mit diesem Befehl als Python Package installiert werden. pip install https://huggingface.co/easyh/de_fnhd_nerdh/resolve/main/de_fnhd_nerdh-any-py3-none-any.whl Jupyter Notebooks Der Code zu diesem Kapitel befindet sich hier: notebooks/04_trainEvaluateModel_spacy.ipynb . Github mybinder.org Hier geht es zum Notebook auf Github Hier geht es zum Jupyter Notebook auf mybinder.org Das Laden des Workspaces wird einen kurzen Moment in Anspruch nehmen.","title":"3.3 Training"},{"location":"tut/#34-evaluierung","text":"Der n\u00e4chste logische Schritt ist jetzt nat\u00fcrlich die Evaluation unseres Modells. Hierf\u00fcr ben\u00f6tigen wir unsere Testdaten. Das Modell wird dann anhand von F-Score , Precision und Recall bewertet. spaCy hat hierf\u00fcr einen einfachen Terminalbefehl. python -m spacy evaluate de_fnhd_nerdh ./data/datensets/trainData.spacy Das Output sollte dann in etwa so aussehen: \u2139 Using CPU ================================== Results ================================== TOK 100.00 NER P 94.85 NER R 91.06 NER F 92.92 SPEED 2297 =============================== NER (per type) =============================== P R F PERSON 94.81 91.41 93.08 ZEIT 92.64 91.89 92.27 ORT 95.94 94.26 95.09 OBJEKT 94.44 81.79 87.66 ORGANISATION 95.59 82.28 88.44 Mit diesen Werten k\u00f6nnen wir ziemlich zufrieden sein. Sollte das allerdings nicht der Fall sein, dann w\u00fcrden wir einfach unseren Trainingsprozess mit kleinen Ver\u00e4nderungen nochmal erneut starten. Allerdings bedeutet der Wert nur, dass das selbst erstellte Modell de_fnhd_nerdh besonders gut mit Texten von Philipp Hainhofer funktioniert (F-Score 0.92), da es mit diesen trainiert wurden. Nur weil ein Text in fr\u00fchneuhochdeutsch geschrieben wurde, ist dies keine Garantie f\u00fcr ein gutes Ergebnis mit diesem Modell. Der Grund: Historische Texte sind zu spezifisch, als dass sie in einem Modell zusammengefasst werden k\u00f6nnten. Interaktive Notebooks Der Code zu diesem Kapitel befindet sich hier: notebooks/04_trainEvaluateModel_spacy.ipynb . mybinder.org Github Hier geht es zum Jupyter Notebook auf mybinder.org Das Laden des Workspaces wird einen kurzen Moment in Anspruch nehmen. Hier geht es zum Notebook auf Github spaCy. Industrial-strength Natural Language Processing in Python. https://spacy.io/ \u21a9 spaCy. Industrial-strength Natural Language Processing in Python. https://spacy.io/usage \u21a9 spaCy. Industrial-strength Natural Language Processing in Python. https://spacy.io/models/de \u21a9 Schumacher, M. K. (2020). Named Entity Recognition und Reverse Engineering. Lebe lieber literarisch. https://lebelieberliterarisch.de/ named-entity-recognition-und-reverse-engineering/ \u21a9 datasolut GmbH. (2021). Was sind Trainingsdaten im Machine Learning? - datasolut Wiki. https://datasolut.com/wiki/trainingsdaten-und-testdaten-machine-learning/ \u21a9","title":"3.4 Evaluierung"}]}